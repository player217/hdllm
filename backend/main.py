import os
import re
import logging
import json
import uuid
import datetime
import urllib.parse
import time
from collections import deque
from contextlib import asynccontextmanager
from textwrap import dedent
from pathlib import Path
import hashlib

import torch
import requests
from fastapi import FastAPI, Request, HTTPException, Depends
from fastapi.responses import Response, StreamingResponse, JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from qdrant_client import QdrantClient, models
from langchain_huggingface import HuggingFaceEmbeddings

# Import GPU acceleration components  
from backend.pipeline.async_pipeline import AsyncPipeline
from backend.common.schemas import AskRequest, IngestRequest
from backend.common.security import cors_kwargs
from backend.common.logging import (
    request_id_ctx, source_ctx, namespace_ctx,
    setup_logging, get_query_hash, set_request_context, clear_request_context,
    # P1-4: Metrics imports
    REQ_COUNT, REQ_LATENCY, RAG_REQ, EMBED_LAT, SEARCH_LAT, QDRANT_ERR,
    CACHE_HITS, CACHE_MISSES, ACTIVE_CONNECTIONS, LLM_TOKENS, prometheus_app
)
from backend.common.config_loader import get_config_loader, QdrantEndpoint

# --------------------------------------------------------------------------
# 1. Enhanced Logging Setup with PII Protection (P1-3)
# --------------------------------------------------------------------------
# Initialize structured logging with PII masking
audit_logger = setup_logging(
    level=os.getenv("LOG_LEVEL", "INFO"),
    format_type=os.getenv("LOG_FORMAT", "json"),
    redact_pii=os.getenv("LOG_REDACT_PII", "true").lower() == "true",
    audit_enabled=os.getenv("SECURITY_AUDIT_ENABLED", "true").lower() == "true"
)

logger = logging.getLogger(__name__)


# --------------------------------------------------------------------------
# 2. ì „ì—­ ë³€ìˆ˜ ë° ì„¤ì •
# --------------------------------------------------------------------------
PROJECT_ROOT = Path(__file__).parent.parent.resolve()
EMBEDDING_MODEL_DEFAULT_PATH = PROJECT_ROOT / "src" / "bin" / "bge-m3-local"

# ë””ë²„ê·¸ ëª¨ë“œ ì„¤ì •
DEBUG_MODE = os.getenv("RAG_DEBUG", "false").lower() == "true"
VERBOSE_LOGGING = os.getenv("RAG_VERBOSE", "false").lower() == "true"

if DEBUG_MODE:
    logger.setLevel(logging.DEBUG)
    logger.info("ğŸ” DEBUG MODE ENABLED")
if VERBOSE_LOGGING:
    logger.info("ğŸ“ VERBOSE LOGGING ENABLED")

try:
    import pythoncom
    import win32com.client
    WIN_COM_AVAILABLE = True
except ImportError:
    WIN_COM_AVAILABLE = False

class AppConfig:
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ì •ì„ ê´€ë¦¬í•©ë‹ˆë‹¤."""
    def __init__(self):
        # Initialize config loader
        self._config_loader = get_config_loader()
        self._qdrant_endpoints = None
        self._load_qdrant_endpoints()
    
    def _load_qdrant_endpoints(self):
        """Load Qdrant endpoints from JSON configuration"""
        try:
            self._qdrant_endpoints = self._config_loader.get_qdrant_endpoints()
            logger.info(f"âœ… Loaded {len(self._qdrant_endpoints)} Qdrant endpoints from JSON config")
        except Exception as e:
            logger.error(f"âŒ Failed to load Qdrant endpoints from JSON config: {e}")
            self._qdrant_endpoints = {}
    
    def get_qdrant_endpoint(self, scope: str) -> QdrantEndpoint:
        """Get Qdrant endpoint configuration for specific scope"""
        if self._qdrant_endpoints and scope in self._qdrant_endpoints:
            return self._qdrant_endpoints[scope]
        
        # Fallback to environment variables
        logger.warning(f"âš ï¸ Using environment variable fallback for {scope} Qdrant endpoint")
        if scope == 'personal':
            return QdrantEndpoint(
                host=os.getenv('QDRANT_PERSONAL_HOST', '127.0.0.1'),
                port=int(os.getenv('QDRANT_PERSONAL_PORT', '6333')),
                timeout=float(os.getenv('QDRANT_PERSONAL_TIMEOUT', '15.0')),
                description='Personal Qdrant (env fallback)'
            )
        elif scope == 'dept':
            return QdrantEndpoint(
                host=os.getenv('QDRANT_DEPT_HOST', '10.150.104.37'),
                port=int(os.getenv('QDRANT_DEPT_PORT', '6333')),
                timeout=float(os.getenv('QDRANT_DEPT_TIMEOUT', '20.0')),
                description='Department Qdrant (env fallback)'
            )
        else:
            # Default fallback
            return QdrantEndpoint(
                host='127.0.0.1',
                port=6333,
                timeout=30.0,
                description=f'Default Qdrant for {scope}'
            )
    
    # Basic application settings
    EMBEDDING_MODEL_PATH: str = str(EMBEDDING_MODEL_DEFAULT_PATH)
    OLLAMA_API_URL: str = os.getenv("RAG_OLLAMA_URL", "http://127.0.0.1:11434/api/chat")
    
    # ì»¬ë ‰ì…˜ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ë¶„ë¦¬ - ë³´ì•ˆÂ·ë¶„ë¦¬ ì„¤ê³„ í•µì‹¬
    # Note: Collection names are now dynamically generated via ResourceManager.get_default_collection_name()
    # This provides centralized collection naming and better maintainability
    
    # ë ˆê±°ì‹œ í˜¸í™˜ì„± (JSON ì„¤ì •ìœ¼ë¡œ ëŒ€ì²´ ì˜ˆì •)
    QDRANT_HOST: str = "localhost"
    QDRANT_PORT: int = 6333
    QDRANT_SCORE_THRESHOLD: float = 0.30  # Lowered threshold to find more results
    QDRANT_SEARCH_LIMIT: int = 3  # Reduce to 3 for faster processing
    QDRANT_TIMEOUT: float = 30.0
    QDRANT_SEARCH_PARAMS: dict = {
        "hnsw_ef": 128,  # Increase for better accuracy (default: 128)
        "exact": False   # Use approximate search for speed
    }
    
    # ë¶„ë¦¬ëœ Qdrant ì¸ìŠ¤í„´ìŠ¤ ì„¤ì • - JSON ì„¤ì •ìœ¼ë¡œ ëŒ€ì²´ë¨
    @property
    def MAIL_QDRANT_HOST(self) -> str:
        personal_ep = self.get_qdrant_endpoint('personal')
        return personal_ep.host
    
    @property
    def MAIL_QDRANT_PORT(self) -> int:
        personal_ep = self.get_qdrant_endpoint('personal')
        return personal_ep.port
        
    @property
    def MAIL_QDRANT_TIMEOUT(self) -> float:
        personal_ep = self.get_qdrant_endpoint('personal')
        return personal_ep.timeout
    
    @property
    def DOC_QDRANT_HOST(self) -> str:
        dept_ep = self.get_qdrant_endpoint('dept')
        return dept_ep.host
        
    @property 
    def DOC_QDRANT_PORT(self) -> int:
        dept_ep = self.get_qdrant_endpoint('dept')
        return dept_ep.port
        
    @property
    def DOC_QDRANT_TIMEOUT(self) -> float:
        dept_ep = self.get_qdrant_endpoint('dept')
        return dept_ep.timeout
    
    DEFAULT_LLM_MODEL: str = "gemma3:4b"
    LLM_TIMEOUT: int = 60
    GREETINGS: list[str] = ["ì•ˆë…•", "ì•ˆë…•í•˜ì„¸ìš”", "ã…ã…‡", "í•˜ì´", "ë°˜ê°€ì›Œ", "ë°˜ê°‘ìŠµë‹ˆë‹¤"]

config = AppConfig()
app_state = {}
dialog_cache: deque[tuple[str, str]] = deque(maxlen=3)

# Embedding cache with LRU (Least Recently Used) eviction
# P1-6: Cache size now configurable via environment variable
embedding_cache = {}
MAX_CACHE_SIZE = int(os.getenv("EMBED_CACHE_MAX", "512"))


# --------------------------------------------------------------------------
# 3. FastAPI ìƒëª…ì£¼ê¸° ë° ì•± ì´ˆê¸°í™”
# --------------------------------------------------------------------------
@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì‹œ ëª¨ë¸ ë° í´ë¼ì´ì–¸íŠ¸ ë¡œë“œ, ì¢…ë£Œ ì‹œ ì •ë¦¬"""
    logger.info("ğŸš€ ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘...")
    logger.info(f"ğŸ“¦ Backend Version: 1.0.4 - Enhanced Security & Stability")
    logger.info(f"ğŸ• Start Time: {datetime.datetime.now().isoformat()}")
    
    # Step 1: Configuration Validation (Critical for stability)
    try:
        from config_validator import validate_startup_config
        validation_result = validate_startup_config()
        
        if not validation_result.is_valid:
            logger.warning("âš ï¸ Configuration validation failed, but continuing with defaults")
            for error in validation_result.errors:
                logger.error(f"  - {error}")
        
        if validation_result.applied_defaults:
            logger.info(f"ğŸ”§ Applied {len(validation_result.applied_defaults)} default configurations")
            
        logger.info("âœ… Configuration validation completed")
    except Exception as e:
        logger.warning(f"âš ï¸ Configuration validation failed: {e}")
        logger.info("Continuing with existing configuration...")
    
    # P1-6: Enhanced device and batch configuration with GPU support
    device_type = "cuda" if torch.cuda.is_available() else "cpu"
    final_device = os.getenv("EMBED_DEVICE", device_type)
    batch_size = int(os.getenv("EMBED_BATCH", "32"))
    
    # Determine optimal dtype based on device
    dtype_str = os.getenv("EMBED_DTYPE", "float16" if final_device == "cuda" else "float32")
    if dtype_str == "float16" and final_device == "cuda":
        torch_dtype = torch.float16
        logger.info(f"ğŸš€ GPU FP16 acceleration enabled")
    else:
        torch_dtype = torch.float32
    
    logger.info(f"âœ… ì‹¤í–‰ ë””ë°”ì´ìŠ¤: {final_device.upper()} (Batch: {batch_size}, Dtype: {dtype_str})")

    try:
        # HuggingFaceEmbeddings doesn't support torch_dtype directly
        model_kwargs = {
            "device": final_device
        }
        
        # GPU-specific optimizations
        if final_device == "cuda":
            batch_size = int(os.getenv("EMBED_BATCH", "64"))  # Larger batch for GPU
            
        app_state["embeddings"] = HuggingFaceEmbeddings(
            model_name=config.EMBEDDING_MODEL_PATH,
            model_kwargs=model_kwargs,
            encode_kwargs={
                "normalize_embeddings": True,
                "batch_size": batch_size,
                "show_progress_bar": False
            }
        )
        logger.info(f"âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì„±ê³µ (device={final_device}, batch={batch_size}, dtype={dtype_str})")
    except Exception as e:
        logger.error(f"âŒ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}", exc_info=True)

    try:
        # ë³´ì•ˆ ê°•í™”ëœ Qdrant í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ResourceManager ì´ˆê¸°í™” í›„ ì—…ë°ì´íŠ¸ë¨)
        try:
            from qdrant_security_config import DEFAULT_SECURITY_CONFIG, create_secure_qdrant_clients
            
            app_state["qdrant_security_config"] = DEFAULT_SECURITY_CONFIG
            app_state["qdrant_clients"] = create_secure_qdrant_clients(DEFAULT_SECURITY_CONFIG)
            
            # ì—°ê²° ìƒíƒœ í™•ì¸
            successful_connections = len(app_state["qdrant_clients"])
            logger.info(f"âœ… {successful_connections}/2 ë³´ì•ˆ Qdrant í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì„±ê³µ (ì„ì‹œ ì„¤ì •)")
            logger.info(f"ğŸ” ì„ì‹œ ì»¬ë ‰ì…˜ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ë¶„ë¦¬: {DEFAULT_SECURITY_CONFIG.collection_namespaces}")
            logger.info("â„¹ï¸ ResourceManager ì´ˆê¸°í™” í›„ ë™ì  ì„¤ì •ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤")
            
        except ImportError:
            logger.error(f"âŒ Qdrant ë³´ì•ˆ ì„¤ì • ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ í´ë¼ì´ì–¸íŠ¸ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
            # ê¸°ë³¸ í´ë¼ì´ì–¸íŠ¸ ì„¤ì • (ë ˆê±°ì‹œ í˜¸í™˜ì„±)
            app_state["qdrant_clients"] = {
                "mail": QdrantClient(host=config.MAIL_QDRANT_HOST, port=config.MAIL_QDRANT_PORT, timeout=15.0),
                "doc": QdrantClient(host=config.DOC_QDRANT_HOST, port=config.DOC_QDRANT_PORT, timeout=20.0)
            }
        except Exception as e:
            logger.error(f"âŒ ë³´ì•ˆ Qdrant í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            # ë ˆê±°ì‹œ ëŒ€ì²´
            app_state["qdrant_clients"] = {
                "mail": QdrantClient(host=config.MAIL_QDRANT_HOST, port=config.MAIL_QDRANT_PORT),
                "doc": QdrantClient(host=config.DOC_QDRANT_HOST, port=config.DOC_QDRANT_PORT)
            }
        
        # ë³´ì•ˆÂ·ë¶„ë¦¬ ì»¬ë ‰ì…˜ ìƒíƒœ í™•ì¸ (ResourceManager í†µí•©)
        if DEBUG_MODE:
            for source_type, client in app_state["qdrant_clients"].items():
                try:
                    collections = client.get_collections()
                    
                    # ResourceManagerë¥¼ í†µí•œ ë™ì  ì»¬ë ‰ì…˜ëª… íšë“
                    resource_manager = app_state.get("resource_manager")
                    expected_collection = None
                    if resource_manager:
                        try:
                            expected_collection = resource_manager.get_default_collection_name(source_type, "my_documents")
                        except Exception as rm_error:
                            logger.warning(f"Failed to get collection name from ResourceManager: {rm_error}")
                            # Fallback to legacy naming
                            legacy_namespaces = {"mail": "mail_my_documents", "doc": "doc_my_documents"}
                            expected_collection = legacy_namespaces.get(source_type)
                    else:
                        # Legacy fallback
                        legacy_namespaces = {"mail": "mail_my_documents", "doc": "doc_my_documents"}
                        expected_collection = legacy_namespaces.get(source_type)
                    
                    logger.debug(f"ğŸ“Š {source_type.upper()} Qdrant ì»¬ë ‰ì…˜ ìƒíƒœ (ê¸°ëŒ€: {expected_collection}):")
                    
                    for col in collections.collections:
                        try:
                            info = client.get_collection(col.name)
                            is_expected = "[âœ…]" if col.name == expected_collection else "[âš ï¸]"
                            logger.debug(f"  {is_expected} Collection '{col.name}': vectors={info.vectors_count}, indexed={info.indexed_vectors_count}")
                        except:
                            logger.debug(f"  [âŒ] Collection '{col.name}': info unavailable")
                            
                    # ê¸°ëŒ€ë˜ëŠ” ì»¬ë ‰ì…˜ì´ ì—†ëŠ” ê²½ìš° ê²½ê³ 
                    collection_names = [col.name for col in collections.collections]
                    if expected_collection and expected_collection not in collection_names:
                        logger.warning(f"âš ï¸ Expected collection '{expected_collection}' not found in {source_type} Qdrant")
                        
                except Exception as e:
                    logger.warning(f"  - {source_type} Qdrant ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")
    except Exception as e:
        logger.error(f"âŒ Qdrant í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì‹¤íŒ¨: {e}", exc_info=True)

    # Phase 2A-1: ResourceManager ì´ˆê¸°í™”
    try:
        from backend.resource_manager import get_resource_manager, ResourceManager
        # Use ResourceManager.from_env() for GPU support
        resource_manager = ResourceManager.from_env()
        app_state["resource_manager"] = resource_manager
        logger.info("ğŸ›ï¸ ResourceManager with GPU acceleration initialized")
        
        # Initialize QdrantRouter for dual routing with JSON configuration
        from backend.common.qdrant_router import QdrantRouter, QdrantConfig
        
        # Get endpoints from JSON configuration
        personal_endpoint = config.get_qdrant_endpoint('personal')
        dept_endpoint = config.get_qdrant_endpoint('dept')
        
        logger.info(f"ğŸ“ Personal Qdrant: {personal_endpoint.host}:{personal_endpoint.port}")
        logger.info(f"ğŸ“ Department Qdrant: {dept_endpoint.host}:{dept_endpoint.port}")
        
        router = QdrantRouter(
            env_name=os.getenv("QDRANT_ENV", "dev"),
            namespace_pattern=os.getenv(
                "NAMESPACE_PATTERN",
                "{scope}_{env}_{source}_my_documents"
            ),
            personal_cfg=QdrantConfig(
                host=personal_endpoint.host,
                port=personal_endpoint.port,
                timeout=personal_endpoint.timeout,
                scope="personal"
            ),
            dept_cfg=QdrantConfig(
                host=dept_endpoint.host,
                port=dept_endpoint.port,
                timeout=dept_endpoint.timeout,
                scope="dept"
            ),
            secure_factory=None  # Will use standard QdrantClient for now
        )
        
        # Store in app state and pass to resource manager
        app_state["qdrant_router"] = router
        resource_manager.qdrant_router = router
        logger.info("ğŸ”€ QdrantRouter initialized for dual routing (personal/dept)")
        
        # Phase 2A-1.5: ìŠ¤íƒ€íŠ¸ì—… ì»¬ë ‰ì…˜ ê²€ì¦ (Fail-Fast ì›ì¹™)
        try:
            logger.info("ğŸ” Starting collection validation (Fail-Fast startup check)...")
            validation_result = await resource_manager.startup_vector_dim_check(
                sources=["mail", "doc"],
                base_name="my_documents",
                auto_create=False  # í”„ë¡œë•ì…˜ì—ì„œëŠ” ìë™ ìƒì„±í•˜ì§€ ì•ŠìŒ
            )
            
            if validation_result["overall_status"] == "success":
                logger.info("âœ… Collection validation passed successfully")
                logger.info(f"ğŸ“Š Validation summary:")
                for source, info in validation_result["collection_status"].items():
                    if info["status"] == "ok":
                        logger.info(f"  â€¢ {source}: Collection exists, dimension={info['dimension']}, vectors={info.get('vector_count', 'N/A')}")
                    else:
                        logger.warning(f"  â€¢ {source}: {info['status']} - {info.get('message', '')}")
                        
                # ì„ë² ë”© ì°¨ì› í™•ì¸
                if "embedding_dimension" in validation_result:
                    logger.info(f"ğŸ”¢ Detected embedding dimension: {validation_result['embedding_dimension']}")
                    
            elif validation_result["overall_status"] == "warning":
                logger.warning("âš ï¸ Collection validation completed with warnings")
                logger.warning(f"ğŸš¨ Issues found: {len(validation_result.get('issues', []))}")
                for issue in validation_result.get("issues", []):
                    logger.warning(f"  â€¢ {issue}")
                logger.info("Application will continue, but some features may be limited")
                
            else:  # error status
                logger.error("âŒ Collection validation FAILED - Application startup aborted")
                logger.error(f"ğŸš¨ Critical issues found: {len(validation_result.get('issues', []))}")
                for issue in validation_result.get("issues", []):
                    logger.error(f"  â€¢ {issue}")
                
                # Fail-Fast: ì»¬ë ‰ì…˜ ë¬¸ì œ ì‹œ ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì¤‘ë‹¨
                raise RuntimeError(
                    f"Collection validation failed: {validation_result.get('summary', 'Unknown error')}. "
                    "Please check Qdrant setup and collection configuration."
                )
                
        except Exception as collection_error:
            logger.error(f"âŒ Collection validation error: {collection_error}")
            if "Collection validation failed" in str(collection_error):
                # ê²€ì¦ ì‹¤íŒ¨ëŠ” ì¹˜ëª…ì  ì˜¤ë¥˜ë¡œ ì²˜ë¦¬
                raise
            else:
                # ê¸°íƒ€ ì˜¤ë¥˜ëŠ” ê²½ê³ ë¡œ ì²˜ë¦¬í•˜ê³  ê³„ì† ì§„í–‰
                logger.warning("âš ï¸ Collection validation encountered an error, continuing with legacy behavior")
                logger.warning("This may cause runtime failures during RAG operations")
        
        # Phase 2A-2: AsyncPipeline ì´ˆê¸°í™”
        app_state["async_pipeline"] = AsyncPipeline(
            resource_manager=resource_manager,
            max_concurrent=resource_manager.config.app_max_concurrency,
            max_queue_size=resource_manager.config.queue_max
        )
        
        # í ì‹œìŠ¤í…œ ì‹œì‘ (ì¤‘ìš”: ì›Œì»¤ë“¤ì´ ì‘ì—…ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡)
        await app_state["async_pipeline"].start_queue()
        logger.info("ğŸš€ AsyncPipeline with TaskQueue system initialized")
        
        # Phase 2A-3: ResourceManager ê¸°ë°˜ ë³´ì•ˆ ì„¤ì • ì—…ë°ì´íŠ¸
        try:
            from qdrant_security_config import create_default_security_config, create_secure_qdrant_clients
            
            # ResourceManagerë¥¼ ì‚¬ìš©í•˜ì—¬ ë™ì  ë³´ì•ˆ ì„¤ì • ìƒì„±
            updated_security_config = create_default_security_config(resource_manager)
            app_state["qdrant_security_config"] = updated_security_config
            
            # ìƒˆë¡œìš´ ì„¤ì •ìœ¼ë¡œ Qdrant í´ë¼ì´ì–¸íŠ¸ ì¬ìƒì„±
            updated_clients = create_secure_qdrant_clients(updated_security_config)
            app_state["qdrant_clients"] = updated_clients
            
            # P1-2 ì „ ì„ì‹œ bridge: ResourceManagerì— clients ì—°ê²°
            class _ClientRegistry:
                def __init__(self, clients_map):
                    self._clients = clients_map
                def get_qdrant_client(self, source):
                    return self._clients.get(source)
            
            resource_manager.clients = _ClientRegistry(updated_clients)
            
            logger.info("âœ… ResourceManager ê¸°ë°˜ ë³´ì•ˆ ì„¤ì •ìœ¼ë¡œ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
            logger.info(f"ğŸ” ë™ì  ì»¬ë ‰ì…˜ ë„¤ì„ìŠ¤í˜ì´ìŠ¤: {updated_security_config.collection_namespaces}")
            
        except Exception as security_update_error:
            logger.warning(f"âš ï¸ ë³´ì•ˆ ì„¤ì • ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {security_update_error}")
            logger.info("ê¸°ì¡´ ì„¤ì •ì„ ìœ ì§€í•©ë‹ˆë‹¤")
        
    except ImportError:
        logger.warning("âš ï¸ ResourceManager not available - using legacy approach")
    except Exception as e:
        logger.error(f"âŒ ResourceManager initialization failed: {e}")
        # ResourceManager ì´ˆê¸°í™” ì‹¤íŒ¨ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ì„ ì¤‘ë‹¨
        raise
    
    yield
    
    logger.info("ğŸŒ™ ì• í”Œë¦¬ì¼€ì´ì…˜ ì¢…ë£Œ...")
    
    # AsyncPipeline TaskQueue ì •ë¦¬
    if "async_pipeline" in app_state:
        try:
            await app_state["async_pipeline"].stop_queue()
            logger.info("âœ… TaskQueue stopped gracefully")
        except Exception as e:
            logger.error(f"âŒ TaskQueue stop failed: {e}")
    
    # ResourceManager ì •ë¦¬
    if "resource_manager" in app_state:
        try:
            await app_state["resource_manager"].cleanup()
            logger.info("âœ… ResourceManager cleanup completed")
        except Exception as e:
            logger.error(f"âŒ ResourceManager cleanup failed: {e}")
    
    app_state.clear()
    dialog_cache.clear()

# Initialize base FastAPI app
app = FastAPI(lifespan=lifespan)

# Phase 2A-2: Circuit Breaker Dashboard Integration
try:
    from circuit_breaker_dashboard import router as dashboard_router
    app.include_router(dashboard_router)
    logger.info("ğŸ”§ Circuit Breaker Dashboard registered")
except ImportError as e:
    logger.warning(f"âš ï¸ Circuit Breaker Dashboard not available: {e}")

# Import security configuration (MANDATORY FOR PRODUCTION)
try:
    from security_config import (
        CORS_CONFIG, 
        QuestionRequest, 
        EnhancedPIIMasker,
        get_current_user,
        SecurityMiddleware,
        sanitize_log_message
    )
    SECURITY_ENABLED = True
    logger.info("ğŸ›¡ï¸ Security module loaded successfully")
except ImportError:
    logger.error("âŒ Security module not found! This is a critical security risk")
    logger.warning("âš ï¸ Falling back to restricted configuration")
    SECURITY_ENABLED = False
    # Use secure CORS configuration from common security module
    CORS_CONFIG = cors_kwargs()

# Phase 3 Integration - Apply comprehensive enhancements
try:
    from integration import create_integrated_app
    
    # Transform app with Phase 3 integration
    app = create_integrated_app(
        existing_app=app,
        enable_security=SECURITY_ENABLED,
        development_mode=DEBUG_MODE
    )
    logger.info("âœ… Phase 3 integration applied successfully")
    
    # Legacy middleware for compatibility (already handled in integration)
    PHASE3_INTEGRATED = True
    
except ImportError as e:
    logger.warning(f"Phase 3 integration not available: {e}")
    PHASE3_INTEGRATED = False
    
    # Fallback to legacy configuration with MANDATORY security
    app.add_middleware(CORSMiddleware, **CORS_CONFIG)
    logger.info(f"ğŸ”’ CORS middleware configured: {len(CORS_CONFIG['allow_origins'])} origins allowed")
    
    # MANDATORY security middleware (always enabled for protection)
    if SECURITY_ENABLED:
        app.add_middleware(SecurityMiddleware)
        logger.info("ğŸ›¡ï¸ Security middleware activated")
        
        # Include authentication routes
        try:
            from auth_routes import router as auth_router
            app.include_router(auth_router)
            logger.info("ğŸ”‘ Authentication routes loaded successfully")
        except ImportError:
            logger.warning("âš ï¸ Authentication routes not available")
    else:
        logger.error("âŒ Running without security middleware - PRODUCTION RISK!")
        logger.warning("Please ensure security_config.py is available")


# --------------------------------------------------------------------------
# 4. Request ID Middleware for correlation (P1-3)
# --------------------------------------------------------------------------
@app.middleware("http")
async def request_id_middleware(request: Request, call_next):
    """
    Request ID middleware for distributed tracing, correlation and metrics (P1-4)
    - Generates or extracts request ID from headers
    - Sets context variables for logging
    - Adds response headers for client correlation
    - Collects HTTP metrics for monitoring
    """
    
    # P1-4: Start timing for latency metrics
    start_time = time.perf_counter()
    
    # Extract or generate request ID
    request_id = request.headers.get("x-request-id")
    if not request_id:
        request_id = str(uuid.uuid4())
    
    # Extract source from query params or path
    source = request.query_params.get("source", "unknown")
    if "/mail" in str(request.url):
        source = "mail"
    elif "/doc" in str(request.url):
        source = "doc"
    
    # Extract scope for dual routing (Header > Query > Default)
    scope = (
        request.headers.get("x-qdrant-scope") or
        request.query_params.get("db_scope") or
        os.getenv("DEFAULT_DB_SCOPE", "personal")
    )
    
    # Validate scope
    if scope not in ["personal", "dept"]:
        logger.warning(f"Invalid scope '{scope}', falling back to personal")
        scope = "personal"
    
    # Set context for logging with scope
    set_request_context(request_id, source, "-", scope)
    
    # Add scope to request state for later use
    request.state.scope = scope
    
    # P1-4: Track active connections
    ACTIVE_CONNECTIONS.inc()
    
    try:
        # Process request
        response = await call_next(request)
        
        # Add correlation headers
        response.headers["x-request-id"] = request_id
        response.headers["x-response-source"] = source
        response.headers["x-used-scope"] = scope  # Add scope for client verification
        
        # Add fallback header if fallback was used
        if getattr(request.state, "fallback_used", False):
            response.headers["x-fallback-used"] = "true"
        
        # P1-4: Record metrics
        duration = time.perf_counter() - start_time
        path = str(request.url.path)
        method = request.method
        status = response.status_code
        
        # Skip metrics endpoint itself to avoid recursion
        if path != "/metrics":
            REQ_COUNT.labels(method=method, path=path, status=str(status)).inc()
            REQ_LATENCY.labels(method=method, path=path).observe(duration)
        
        # Log access for audit
        if audit_logger.enabled:
            audit_logger.log_access(
                resource=path,
                action=method,
                result="success",
                user_id=request.headers.get("x-user-id")
            )
        
        return response
        
    except Exception as e:
        # P1-4: Record error metrics
        duration = time.perf_counter() - start_time
        path = str(request.url.path)
        method = request.method
        
        if path != "/metrics":
            REQ_COUNT.labels(method=method, path=path, status="500").inc()
            REQ_LATENCY.labels(method=method, path=path).observe(duration)
        
        logger.error(f"Request failed: {str(e)}")
        
        # Log failure for audit
        if audit_logger.enabled:
            audit_logger.log_access(
                resource=path,
                action=method,
                result="error",
                user_id=request.headers.get("x-user-id")
            )
        raise
        
    finally:
        # P1-4: Decrement active connections
        ACTIVE_CONNECTIONS.dec()
        # Clear context
        clear_request_context()


# --------------------------------------------------------------------------
# 5. í•µì‹¬ ë¡œì§ í•¨ìˆ˜ (ì´ì „ ì„¹ì…˜ 4ë¥¼ 5ë¡œ ë³€ê²½)
# --------------------------------------------------------------------------

def _get_current_namespace_mapping():
    """í˜„ì¬ ResourceManager ì„¤ì •ì— ë”°ë¥¸ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ë§¤í•‘ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    resource_manager = app_state.get("resource_manager")
    if resource_manager:
        try:
            # ResourceManagerë¥¼ í†µí•œ ë™ì  ë§¤í•‘ ìƒì„±
            return {
                "mail": resource_manager.get_default_collection_name("mail", "my_documents"),
                "doc": resource_manager.get_default_collection_name("doc", "my_documents")
            }
        except Exception as e:
            logger.warning(f"Failed to get namespace mapping from ResourceManager: {e}")
    
    # Fallback to legacy mapping
    return {
        "mail": "mail_my_documents", 
        "doc": "doc_my_documents"
    }


def format_context(payload: dict) -> str:
    """ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ë¥¼ LLM í”„ë¡¬í”„íŠ¸ì— ë§ê²Œ í¬ë§·í•©ë‹ˆë‹¤."""
    source_type = payload.get("source_type")
    raw_text = payload.get("text", "") or payload.get("body", "")
    raw_text = raw_text.strip()
    
    # Limit context length for faster processing
    MAX_CONTEXT_LENGTH = 500
    if len(raw_text) > MAX_CONTEXT_LENGTH:
        raw_text = raw_text[:MAX_CONTEXT_LENGTH] + "..."
    
    if VERBOSE_LOGGING:
        logger.debug(f"format_context - source_type: {source_type}")
        logger.debug(f"format_context - available fields: {list(payload.keys())}")

    if source_type in ["email_body", "email_attachment"]:
        is_attachment = source_type == 'email_attachment'
        attachment_info = f"- ì²¨ë¶€íŒŒì¼ëª…: {payload.get('file_name', 'N/A')}\n" if is_attachment else ""
        
        # [ìˆ˜ì •] ì œëª©ê³¼ ë‚ ì§œë¥¼ ìœ ì—°í•˜ê²Œ ê°€ì ¸ì˜¤ë„ë¡ ë³€ê²½
        title = payload.get("mail_subject") or payload.get("subject", "N/A")
        date = payload.get("sent_date") or payload.get("date", "N/A")
        
        if VERBOSE_LOGGING:
            logger.debug(f"format_context - title: {title[:50] if title != 'N/A' else 'N/A'}")
            logger.debug(f"format_context - date: {date}")
            if title == "N/A":
                logger.warning(f"format_context - Missing title field. Available: {list(payload.keys())}")
            if date == "N/A":
                logger.warning(f"format_context - Missing date field. Available: {list(payload.keys())}")

        return dedent(f"""\
            [ì°¸ê³ ìë£Œ: ì´ë©”ì¼ {'ì²¨ë¶€íŒŒì¼' if is_attachment else 'ë³¸ë¬¸'}]
            - ì œëª©: {title}
            - ë³´ë‚¸ ì‚¬ëŒ: {payload.get('sender', 'N/A')}
            - ë‚ ì§œ: {date}
            {attachment_info}- ë‚´ìš©:
            {raw_text}""").strip()
    
    return f"[ì°¸ê³ ìë£Œ: ê¸°íƒ€]\n{raw_text}"

async def stream_llm_response(prompt: str, model: str, request_id: str):
    """Stream LLM response via ResourceManager"""
    logger.info(f"[{request_id}] LLM streaming via ResourceManager (model: {model})...")
    
    try:
        rm = app_state["resource_manager"]
        async_gen = await rm.generate_llm_response(prompt, model, stream=True)
        async for token in async_gen:
            # NDJSON/SSE ì–´ë–¤ í˜•ì‹ì´ë“  ìƒìœ„ì—ì„œ ë˜í•‘í•˜ë¯€ë¡œ ì—¬ê¸°ì„  í…ìŠ¤íŠ¸ë§Œ í† ìŠ¤
            yield token
    except Exception as e:
        logger.error(f"[{request_id}] LLM ìŠ¤íŠ¸ë¦¬ë° ì‹¤íŒ¨: {e}")
        yield "ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

def search_qdrant(question: str, request_id: str, client: QdrantClient, config: AppConfig, source: str = "mail", request: Request = None) -> tuple[str, list[dict]]:
    """Qdrantì—ì„œ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    import time
    start_time = time.time()
    
    embeddings = app_state.get("embeddings")
    if not client or not embeddings:
        logger.warning(f"[{request_id}] Qdrant client or embeddings not available")
        return "", []

    # ì¿¼ë¦¬ ì •ê·œí™” ë° ë²¡í„° ìƒì„±
    normalized_query = question.lower().strip()
    logger.debug(f"[{request_id}] Query normalization: '{question}' -> '{normalized_query}'")
    
    # íŠ¹ì • í‚¤ì›Œë“œ ê°ì§€ (ë””ë²„ê¹…ìš©)
    if "ë¥´ê¼¬ë„" in question:
        logger.info(f"[{request_id}] ğŸ” Special keyword 'ë¥´ê¼¬ë„' detected in query")
    
    # Check embedding cache first
    cache_key = hashlib.md5(normalized_query.encode()).hexdigest()
    if cache_key in embedding_cache:
        query_vector = embedding_cache[cache_key]
        logger.debug(f"[{request_id}] ğŸ¯ Using cached embedding for query")
        # P1-4: Record cache hit
        CACHE_HITS.labels(cache_type="embedding").inc()
    else:
        # P1-4: Start embedding timing
        embed_start = time.perf_counter()
        
        # P1-6: Use inference_mode for better performance
        if hasattr(torch, 'inference_mode'):
            with torch.inference_mode():
                query_vector = embeddings.embed_query(normalized_query)
        else:
            query_vector = embeddings.embed_query(normalized_query)
        
        # P1-4: Record embedding latency
        EMBED_LAT.labels(backend="huggingface").observe(time.perf_counter() - embed_start)
        # P1-4: Record cache miss
        CACHE_MISSES.labels(cache_type="embedding").inc()
        
        # Add to cache with size limit
        if len(embedding_cache) >= MAX_CACHE_SIZE:
            # Remove oldest item (simple FIFO for now)
            oldest_key = next(iter(embedding_cache))
            del embedding_cache[oldest_key]
        
        embedding_cache[cache_key] = query_vector
        logger.debug(f"[{request_id}] ğŸ’¾ Cached new embedding (cache size: {len(embedding_cache)})")
    
    logger.debug(f"[{request_id}] Query vector created - dimension: {len(query_vector)}")

    # ë³´ì•ˆÂ·ë¶„ë¦¬ ì„¤ê³„: ì†ŒìŠ¤ë³„ ì „ìš© ì»¬ë ‰ì…˜ ê²€ìƒ‰ (ResourceManager í†µí•©)
    resource_manager = app_state.get("resource_manager")
    if resource_manager:
        try:
            collection_name = resource_manager.get_default_collection_name(source, "my_documents")
            logger.debug(f"[{request_id}] ğŸ·ï¸ Collection name from ResourceManager: {collection_name}")
        except Exception as e:
            logger.error(f"[{request_id}] âŒ Failed to get collection name from ResourceManager: {e}")
            return "", []
    else:
        # Fallback to legacy naming for backward compatibility
        legacy_namespaces = {"mail": "mail_my_documents", "doc": "doc_my_documents"}
        collection_name = legacy_namespaces.get(source)
        if not collection_name:
            logger.error(f"[{request_id}] âŒ ì§€ì›ë˜ì§€ ì•ŠëŠ” ì†ŒìŠ¤ íƒ€ì…: {source}")
            return "", []
        logger.warning(f"[{request_id}] âš ï¸ Using legacy collection naming: {collection_name}")
    
    all_hits = []
    try:
        logger.info(f"[{request_id}] ğŸ” Searching namespace-separated collection: '{collection_name}' (source: {source})")
        logger.debug(f"[{request_id}] Search params - limit: {config.QDRANT_SEARCH_LIMIT}, threshold: {config.QDRANT_SCORE_THRESHOLD}")
        
        # ResourceManager í†µí•© ê²€ìƒ‰ ì‚¬ìš© (P1-2)
        try:
            import asyncio
            
            # P1-4: Start search timing
            search_start = time.perf_counter()
            
            # ResourceManagerì˜ í†µí•© ê²€ìƒ‰ ë©”ì„œë“œ ì‚¬ìš©
            if asyncio.iscoroutinefunction(resource_manager.search_vectors):
                # ë¹„ë™ê¸° í˜¸ì¶œì„ ë™ê¸°ì ìœ¼ë¡œ ì‹¤í–‰
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                try:
                    search_results = loop.run_until_complete(
                        resource_manager.search_vectors(
                            source_type=source,
                            query_vector=query_vector,
                            limit=config.QDRANT_SEARCH_LIMIT,
                            score_threshold=config.QDRANT_SCORE_THRESHOLD,
                            with_payload=True,
                            with_vectors=False,
                            search_params=models.SearchParams(**config.QDRANT_SEARCH_PARAMS),
                            request=request
                        )
                    )
                finally:
                    loop.close()
            else:
                search_results = resource_manager.search_vectors(
                    source_type=source,
                    query_vector=query_vector,
                    limit=config.QDRANT_SEARCH_LIMIT,
                    score_threshold=config.QDRANT_SCORE_THRESHOLD,
                    with_payload=True,
                    with_vectors=False,
                    search_params=models.SearchParams(**config.QDRANT_SEARCH_PARAMS),
                    request=request
                )
            
            # P1-4: Record search latency
            SEARCH_LAT.labels(backend="qdrant", source=source).observe(time.perf_counter() - search_start)
            
            # ê²°ê³¼ í˜•ì‹ ë³€í™˜ (ResourceManager í˜•ì‹ â†’ Qdrant í˜•ì‹)
            hits = []
            for result in search_results:
                hit = type('ScoredPoint', (), {})()
                hit.id = result.get('id', '')
                hit.score = result.get('score', 0.0)
                hit.payload = result.get('payload', {})
                hits.append(hit)
                
        except Exception as e:
            logger.error(f"ResourceManager search failed, falling back: {e}")
            # P1-4: Record Qdrant error
            QDRANT_ERR.labels(type="search_error").inc()
            # í´ë°±: ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
            if hasattr(client, 'search') and hasattr(client, 'config'):
                hits = client.search(
                    query_vector=query_vector,
                    limit=config.QDRANT_SEARCH_LIMIT,
                    score_threshold=config.QDRANT_SCORE_THRESHOLD,
                    search_params=models.SearchParams(**config.QDRANT_SEARCH_PARAMS)
                )
            else:
                hits = client.search(
                    collection_name=collection_name,
                    query_vector=query_vector,
                    limit=config.QDRANT_SEARCH_LIMIT,
                    score_threshold=config.QDRANT_SCORE_THRESHOLD,
                    search_params=models.SearchParams(**config.QDRANT_SEARCH_PARAMS)
                )
        
        if hits:
            logger.info(f"[{request_id}] âœ… Found {len(hits)} hits in '{collection_name}'")
            if DEBUG_MODE:
                for i, hit in enumerate(hits[:5], 1):  # ìƒìœ„ 5ê°œë§Œ ìƒì„¸ ë¡œê¹…
                    logger.debug(f"[{request_id}]   Hit {i}: score={hit.score:.4f}, id={hit.id}")
                    logger.debug(f"[{request_id}]   Metadata keys: {list(hit.payload.keys())}")
                    if VERBOSE_LOGGING:
                        # ë©”íƒ€ë°ì´í„° ì¼ë¶€ ì¶œë ¥ (í…ìŠ¤íŠ¸ ì œì™¸)
                        meta_preview = {k: v for k, v in hit.payload.items() if k != 'text' and k != 'embedding'}
                        logger.debug(f"[{request_id}]   Metadata preview: {meta_preview}")
        else:
            logger.warning(f"[{request_id}] âš ï¸ No hits found in '{collection_name}' (threshold: {config.QDRANT_SCORE_THRESHOLD})")
        
        all_hits.extend(hits)
    except Exception as e:
        logger.error(f"[{request_id}] âŒ ì»¬ë ‰ì…˜ '{collection_name}' ê²€ìƒ‰ ì‹¤íŒ¨: {e}", exc_info=DEBUG_MODE)
        # ë³´ì•ˆ ê°•í™”: ì˜ˆì™¸ ìƒí™©ì—ì„œë„ ë¹ˆ ê²°ê³¼ ë°˜í™˜
        return "", []

    if not all_hits:
        logger.warning(f"[{request_id}] âŒ No hits found in collection '{collection_name}'")
        return "", []

    # Audit log for vector search
    query_hash = get_query_hash(normalized_query)
    audit_logger.log_search(
        source=source,
        namespace=collection_name,
        query_hash=query_hash,
        limit=config.QDRANT_SEARCH_LIMIT,
        threshold=config.QDRANT_SCORE_THRESHOLD,
        result_count=len(all_hits),
        latency_ms=(time.time() - start_time) * 1000
    )

    # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
    logger.info(f"[{request_id}] ğŸ“Š Total hits before deduplication: {len(all_hits)}")
    unique_hits = {hit.id: hit for hit in sorted(all_hits, key=lambda x: x.score, reverse=True)}.values()
    logger.info(f"[{request_id}] ğŸ“Š Total hits after deduplication: {len(unique_hits)}")
    
    top_hits = sorted(list(unique_hits), key=lambda x: x.score, reverse=True)[:config.QDRANT_SEARCH_LIMIT]
    logger.info(f"[{request_id}] ğŸ“Š Final top hits selected: {len(top_hits)}")
    
    # ìƒì„¸í•œ ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥
    logger.info(f"[{request_id}] " + "=" * 60)
    logger.info(f"[{request_id}] ğŸ” QDRANT ê²€ìƒ‰ ê²°ê³¼ ìƒì„¸")
    logger.info(f"[{request_id}] " + "=" * 60)
    
    for i, hit in enumerate(top_hits, 1):
        title = hit.payload.get("mail_subject") or hit.payload.get("subject", "N/A")
        date = hit.payload.get("sent_date") or hit.payload.get("date", "N/A")
        sender = hit.payload.get("sender", "N/A")
        text = hit.payload.get("text", "")
        text_preview = text[:300] + "..." if len(text) > 300 else text
        
        logger.info(f"[{request_id}] ğŸ“„ ë¬¸ì„œ {i}:")
        logger.info(f"[{request_id}]   ì ìˆ˜: {hit.score:.4f}")
        logger.info(f"[{request_id}]   ì œëª©: {title}")
        logger.info(f"[{request_id}]   ë°œì‹ ì: {sender}")
        logger.info(f"[{request_id}]   ë‚ ì§œ: {date}")
        logger.info(f"[{request_id}]   í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°:")
        logger.info(f"[{request_id}]   {text_preview}")
        logger.info(f"[{request_id}] " + "-" * 40)
        
        if DEBUG_MODE and hit.score < 0.6:
            logger.warning(f"[{request_id}]   âš ï¸ Low score detected: {hit.score:.4f}")

    contexts = [format_context(hit.payload) for hit in top_hits]
    
    # í¬ë§·íŒ…ëœ ì»¨í…ìŠ¤íŠ¸ ë¡œê¹…
    if VERBOSE_LOGGING and contexts:
        logger.info(f"[{request_id}] " + "=" * 60)
        logger.info(f"[{request_id}] ğŸ“ í¬ë§·íŒ…ëœ ì»¨í…ìŠ¤íŠ¸")
        logger.info(f"[{request_id}] " + "=" * 60)
        for i, ctx in enumerate(contexts, 1):
            logger.info(f"[{request_id}] ì»¨í…ìŠ¤íŠ¸ {i}:")
            logger.info(f"[{request_id}] {ctx[:500]}..." if len(ctx) > 500 else f"[{request_id}] {ctx}")
            logger.info(f"[{request_id}] " + "-" * 40)
    
    references = []
    for hit in top_hits:
        if source == "mail":
            # ë©”ì¼ ëª¨ë“œ: ë©”ì¼ ë§í¬ ì²˜ë¦¬
            link_value = hit.payload.get("link")
            if link_value:
                # Debug logging for link
                logger.info(f"[{request_id}] Found mail link: {link_value[:50]}...")
                
                ref_title = hit.payload.get("mail_subject") or hit.payload.get("subject", "N/A")
                ref_date = hit.payload.get("sent_date") or hit.payload.get("date", "N/A")
                references.append({
                    "title": ref_title,
                    "date": ref_date,
                    "sender": hit.payload.get("sender", "N/A"),
                    "link": link_value,
                    "entry_id": hit.payload.get("entry_id") or hit.payload.get("mail_id"),
                    "display_url": hit.payload.get("display_url"),
                    "type": "mail"
                })
            else:
                logger.warning(f"[{request_id}] No link found in mail payload. Available keys: {list(hit.payload.keys())}")
        else:  # source == "doc"
            # ë¬¸ì„œ ëª¨ë“œ: íŒŒì¼ ê²½ë¡œ ì²˜ë¦¬
            # íŒŒì¼ ê²½ë¡œëŠ” ë‹¤ì–‘í•œ í•„ë“œëª…ìœ¼ë¡œ ì €ì¥ë  ìˆ˜ ìˆìŒ
            file_path = (hit.payload.get("file_path") or 
                        hit.payload.get("document_path") or 
                        hit.payload.get("path") or 
                        hit.payload.get("link"))
            
            if file_path:
                # ë¬¸ì„œ ì œëª© ì¶”ì¶œ
                doc_title = (hit.payload.get("title") or 
                           hit.payload.get("document_name") or 
                           hit.payload.get("filename") or 
                           hit.payload.get("name") or 
                           "ë¬¸ì„œ")
                
                # ë¬¸ì„œ ë‚ ì§œ ì¶”ì¶œ
                doc_date = (hit.payload.get("created_date") or 
                          hit.payload.get("modified_date") or 
                          hit.payload.get("date") or 
                          "N/A")
                
                references.append({
                    "title": doc_title,
                    "date": doc_date,
                    "path": file_path,
                    "type": "document"
                })

    return "\n\n---\n\n".join(contexts), references


# --------------------------------------------------------------------------
# 5. API ì—”ë“œí¬ì¸íŠ¸
# --------------------------------------------------------------------------
@app.get("/")
def root():
    """API ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸ - API ì •ë³´ ì œê³µ"""
    return {
        "name": "Gauss-1 Backend API",
        "version": "1.0.0",
        "status": "running",
        "endpoints": {
            "GET /": "API information",
            "GET /health": "Health check",
            "GET /status": "Service status check",
            "POST /ask": "RAG question answering",
            "GET /open_mail": "Open mail in Outlook (Windows only)"
        },
        "description": "HDí˜„ëŒ€ë¯¸í¬ ì„ ê°ê¸°ìˆ ë¶€ RAG ì‹œìŠ¤í…œ ë°±ì—”ë“œ"
    }

@app.get("/health")
def health_check():
    return {"status": "ok"}

@app.get("/status")
async def status():
    """ë³´ì•ˆÂ·ë¶„ë¦¬ ì„¤ê³„ê°€ ì ìš©ëœ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸ (Dual Routing í¬í•¨)"""
    import asyncio
    import aiohttp
    
    async def ping_async(url, timeout=1.0):
        """ë¹„ë™ê¸°ë¡œ ì„œë¹„ìŠ¤ ìƒíƒœë¥¼ ì²´í¬í•©ë‹ˆë‹¤."""
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(url, timeout=aiohttp.ClientTimeout(total=timeout)) as response:
                    return response.status == 200
        except Exception:
            return False
    
    # Check if QdrantRouter is available for dual routing
    router = app_state.get("qdrant_router")
    if router:
        # Get aggregated status from router
        router_status = await router.get_aggregated_status()
    else:
        router_status = None
    
    # ê¸°ë³¸ ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸ (legacy compatibility)
    ollama_url = config.OLLAMA_API_URL.replace("/api/chat", "/")
    qdrant_mail_url = f"http://{config.MAIL_QDRANT_HOST}:{config.MAIL_QDRANT_PORT}/"
    qdrant_doc_url = f"http://{config.DOC_QDRANT_HOST}:{config.DOC_QDRANT_PORT}/"
    
    basic_results = await asyncio.gather(
        ping_async(ollama_url),
        ping_async(qdrant_mail_url),
        ping_async(qdrant_doc_url),
        return_exceptions=True
    )
    
    # ë³´ì•ˆ í´ë¼ì´ì–¸íŠ¸ ìƒíƒœ í™•ì¸
    security_status = {}
    if "qdrant_clients" in app_state:
        for source_type, client in app_state["qdrant_clients"].items():
            try:
                if hasattr(client, 'health_check'):
                    # SecureQdrantClient ì‚¬ìš©
                    health_info = client.health_check()
                    security_status[f"secure_{source_type}"] = {
                        "connected": health_info.get("connection_ok", False),
                        "collection_exists": health_info.get("collection_exists", False),
                        "namespace": health_info.get("collection_namespace", "unknown"),
                        "vectors_count": health_info.get("vectors_count", 0),
                        "security_enabled": True
                    }
                else:
                    # ë ˆê±°ì‹œ í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš©
                    collections = client.get_collections()
                    security_status[f"legacy_{source_type}"] = {
                        "connected": True,
                        "collections_count": len(collections.collections),
                        "security_enabled": False
                    }
            except Exception as e:
                security_status[f"error_{source_type}"] = {
                    "connected": False,
                    "error": str(e)[:100],  # ì—ëŸ¬ ë©”ì‹œì§€ ê¸¸ì´ ì œí•œ
                    "security_enabled": False
                }
    
    # ë³´ì•ˆ ì„¤ì • ì •ë³´
    security_config_info = {}
    if "qdrant_security_config" in app_state:
        sec_config = app_state["qdrant_security_config"]
        security_config_info = {
            "namespaces_configured": len(sec_config.collection_namespaces),
            "allowed_sources": sec_config.allowed_sources,
            "max_search_limit": sec_config.max_search_limit,
            "audit_logging": sec_config.audit_logging,
            "ssl_enabled": sec_config.enable_ssl
        }
    
    status_response = {
        # ê¸°ë³¸ ì„œë¹„ìŠ¤ ìƒíƒœ
        "fastapi": True,
        "ollama": basic_results[0] if not isinstance(basic_results[0], Exception) else False,
        "qdrant_mail": basic_results[1] if not isinstance(basic_results[1], Exception) else False,
        "qdrant_doc": basic_results[2] if not isinstance(basic_results[2], Exception) else False,
        
        # ë³´ì•ˆÂ·ë¶„ë¦¬ ì„¤ê³„ ìƒíƒœ
        "security_clients": security_status,
        "security_config": security_config_info,
        "namespace_separation": _get_current_namespace_mapping(),
        
        # ì‹œìŠ¤í…œ ì •ë³´
        "timestamp": datetime.datetime.now().isoformat(),
        "version": "2.0.0-security",
        "phase": "2A-0 ë³´ì•ˆÂ·ë¶„ë¦¬ ì„¤ê³„ ì ìš©ë¨"
    }
    
    # Add dual routing status if available
    if router_status:
        status_response.update(router_status)
    
    return status_response


# --------------------------------------------------------------------------
# P1-4: Metrics endpoint for Prometheus monitoring
# --------------------------------------------------------------------------
@app.get("/metrics")
async def get_metrics(request: Request):
    """
    Prometheus metrics endpoint (P1-4)
    - Security: Only accessible from localhost for security
    - Returns metrics in Prometheus text format
    """
    from prometheus_client import generate_latest
    from fastapi.responses import PlainTextResponse
    
    # Security check: only allow localhost access
    client_host = request.client.host if request.client else None
    if client_host not in ["127.0.0.1", "localhost", "::1"]:
        raise HTTPException(status_code=403, detail="Metrics only accessible from localhost")
    
    # Generate metrics using the registry from logging module
    from backend.common.logging import registry
    metrics = generate_latest(registry)
    
    return PlainTextResponse(content=metrics.decode('utf-8'), media_type="text/plain; version=0.0.4")


@app.post("/open_file")
async def open_file(request: Request):
    """íŒŒì¼ ê²½ë¡œë¥¼ ë°›ì•„ì„œ íŒŒì¼ì„ ì—½ë‹ˆë‹¤ (ë¶€ì„œ ë¬¸ì„œìš©)."""
    try:
        body = await request.json()
        file_path = body.get("file_path", "")
        
        logger.info(f"ë°›ì€ íŒŒì¼ ê²½ë¡œ: {file_path}")
        
        if not file_path:
            raise HTTPException(status_code=400, detail="íŒŒì¼ ê²½ë¡œê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        
        # Handle various path formats
        # Remove quotes if present
        file_path = file_path.strip('"').strip("'")
        
        # Handle file:// URLs
        if file_path.startswith('file:///'):
            # Convert file:///C:/path to C:/path
            file_path = file_path[8:]  # Remove 'file:///'
        elif file_path.startswith('file://'):
            # Convert file://path to path
            file_path = file_path[7:]  # Remove 'file://'
        
        # Convert forward slashes to backslashes for Windows
        if os.name == 'nt':
            file_path = file_path.replace('/', '\\')
        
        logger.info(f"ì²˜ë¦¬ëœ íŒŒì¼ ê²½ë¡œ: {file_path}")
        
        # Check if file exists
        if os.path.exists(file_path):
            if os.name == 'nt':
                # Windowsì—ì„œ os.startfile ì‚¬ìš©
                os.startfile(file_path)
                logger.info(f"íŒŒì¼ ì—´ê¸° ì„±ê³µ: {file_path}")
                return {"status": "success", "message": "íŒŒì¼ì„ ì—´ì—ˆìŠµë‹ˆë‹¤."}
            else:
                # Non-Windows ì‹œìŠ¤í…œì—ì„œëŠ” ì§€ì›í•˜ì§€ ì•ŠìŒ
                raise HTTPException(status_code=501, detail="íŒŒì¼ ì—´ê¸°ëŠ” Windows í™˜ê²½ì—ì„œë§Œ ì§€ì›ë©ë‹ˆë‹¤.")
        else:
            logger.error(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
            raise HTTPException(status_code=404, detail=f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
                
    except HTTPException:
        # HTTPExceptionì€ ê·¸ëŒ€ë¡œ ë‹¤ì‹œ ë°œìƒ
        raise
    except Exception as e:
        logger.error(f"íŒŒì¼ ì—´ê¸° ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"íŒŒì¼ ì—´ê¸° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

@app.post("/open-mail")
async def open_mail(request: Request):
    """í†µí•©ëœ ë©”ì¼/íŒŒì¼ ì—´ê¸° ì—”ë“œí¬ì¸íŠ¸ (POST ë°©ì‹)"""
    import webbrowser
    
    body = await request.json()
    
    # ë‹¤ì–‘í•œ í‚¤ ì´ë¦„ ì§€ì›
    entry_id = body.get("entry_id") or body.get("id") or body.get("link_key", "")
    display_url = body.get("display_url") or body.get("link") or body.get("url", "")
    
    # link_keyê°€ ìˆìœ¼ë©´ ë””ì½”ë”©
    if entry_id:
        entry_id = urllib.parse.unquote(entry_id)
    
    # 1. file:/// ìŠ¤í‚¤ë§ˆ ì²˜ë¦¬
    if entry_id and entry_id.startswith("file:///"):
        try:
            path = urllib.parse.unquote(entry_id[8:])
            if os.path.exists(path):
                os.startfile(path)
                return {"ok": True, "via": "file", "path": path}
            else:
                raise FileNotFoundError(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path}")
        except Exception as e:
            logger.error(f"íŒŒì¼ ì—´ê¸° ì‹¤íŒ¨: {e}")
            raise HTTPException(status_code=400, detail=str(e))
    
    # 2. HTTP(S) ì›¹ ë§í¬ ì²˜ë¦¬
    if display_url and display_url.startswith(("http://", "https://")):
        try:
            webbrowser.open(display_url)
            return {"ok": True, "via": "web", "url": display_url}
        except Exception as e:
            logger.error(f"ì›¹ ë§í¬ ì—´ê¸° ì‹¤íŒ¨: {e}")
    
    # 3. outlook:// ìŠ¤í‚¤ë§ˆ ì²˜ë¦¬
    if entry_id and entry_id.startswith("outlook://"):
        if not WIN_COM_AVAILABLE:
            raise HTTPException(status_code=501, detail="Outlook ì—°ë™ì´ í•„ìš”í•©ë‹ˆë‹¤(Windows/pywin32).")
        
        pythoncom.CoInitialize()
        try:
            mapi_id = entry_id[10:]  # outlook:// ì œê±°
            outlook = win32com.client.Dispatch("Outlook.Application")
            mapi_ns = outlook.GetNamespace("MAPI")
            item = mapi_ns.GetItemFromID(mapi_id)
            item.Display(True)
            return {"ok": True, "via": "outlook", "entry_id": mapi_id}
        except Exception as e:
            logger.error(f"Outlook ë©”ì¼ ì—´ê¸° ì‹¤íŒ¨: {e}")
            raise HTTPException(status_code=500, detail=f"Outlook ë©”ì¼ ì—´ê¸° ì‹¤íŒ¨: {e}")
        finally:
            pythoncom.CoUninitialize()
    
    # 4. ì¼ë°˜ EntryID ì²˜ë¦¬ (outlook:// ì—†ì´)
    if entry_id and not entry_id.startswith(("file://", "http://", "https://")):
        if not WIN_COM_AVAILABLE:
            raise HTTPException(status_code=501, detail="Outlook ì—°ë™ì´ í•„ìš”í•©ë‹ˆë‹¤(Windows/pywin32).")
        
        pythoncom.CoInitialize()
        try:
            outlook = win32com.client.Dispatch("Outlook.Application")
            mapi_ns = outlook.GetNamespace("MAPI")
            item = mapi_ns.GetItemFromID(entry_id)
            item.Display(True)
            return {"ok": True, "via": "mapi", "entry_id": entry_id}
        except Exception as e:
            logger.error(f"MAPI ë©”ì¼ ì—´ê¸° ì‹¤íŒ¨: {e}")
            raise HTTPException(status_code=500, detail=f"MAPI ë©”ì¼ ì—´ê¸° ì‹¤íŒ¨: {e}")
        finally:
            pythoncom.CoUninitialize()
    
    # ì•„ë¬´ê²ƒë„ ì œê³µë˜ì§€ ì•Šì€ ê²½ìš°
    raise HTTPException(status_code=400, detail="entry_id ë˜ëŠ” display_urlì´ í•„ìš”í•©ë‹ˆë‹¤.")

@app.post("/ask")
async def ask(ask_request: AskRequest, request: Request):
    """GPU ê°€ì† RAG ë‹µë³€ì„ ìŠ¤íŠ¸ë¦¬ë°í•©ë‹ˆë‹¤."""
    request_id = ask_request.request_id
    logger.info(f"ğŸš€ GPU RAG REQUEST START: {request_id}")

    try:
        # P1-4: Start RAG timing
        rag_start = time.perf_counter()
        
        # AsyncPipeline ì‚¬ìš© ì—¬ë¶€ í™•ì¸
        async_pipeline = app_state.get("async_pipeline")
        if async_pipeline:
            # GPU ê°€ì† ê²½ë¡œ
            result = await ask_with_gpu_acceleration(ask_request, async_pipeline, request)
            # P1-4: Record successful RAG request
            RAG_REQ.labels(source=ask_request.source.value, result="success").inc()
            return result
        else:
            # ë ˆê±°ì‹œ ê²½ë¡œ (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)
            result = await ask_legacy(ask_request, request)
            # P1-4: Record successful RAG request
            RAG_REQ.labels(source=ask_request.source.value, result="success").inc()
            return result
    
    except Exception as e:
        # P1-4: Record failed RAG request
        RAG_REQ.labels(source=ask_request.source.value, result="error").inc()
        logger.error(f"âŒ RAG request failed: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Internal server error: {str(e)}")


async def ask_with_gpu_acceleration(ask_request: AskRequest, pipeline: AsyncPipeline, request: Request):
    """GPU ê°€ì†ì„ ì‚¬ìš©í•œ ìƒˆë¡œìš´ RAG ì—”ë“œí¬ì¸íŠ¸"""
    request_id = ask_request.request_id
    
    # ì¸ì‚¬ë§ ì²´í¬
    if any(greet in ask_request.query for greet in config.GREETINGS):
        async def greeting_stream():
            yield json.dumps({
                "status": "completed",
                "content": "ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?", 
                "references": [],
                "metadata": {"request_id": request_id, "gpu_accelerated": True}
            }, ensure_ascii=False)
        return StreamingResponse(greeting_stream(), media_type="application/x-ndjson")
    
    try:
        # GPU ê°€ì† ê²€ìƒ‰ ì‹¤í–‰
        search_result = await pipeline.run_search(
            query=ask_request.query,
            source_type=ask_request.source.value,
            limit=ask_request.top_k,
            score_threshold=0.3
        )
        
        results = search_result["results"]
        metadata = search_result["metadata"]
        
        logger.info(f"[{request_id}] âš¡ GPU search completed: {metadata['total_time_ms']:.1f}ms on {metadata['device']}")
        
        if not results:
            async def no_context_stream():
                yield json.dumps({
                    "status": "completed",
                    "content": "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                    "references": [],
                    "metadata": metadata
                }, ensure_ascii=False)
            return StreamingResponse(no_context_stream(), media_type="application/x-ndjson")
        
        # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        context_parts = []
        references = []
        
        for i, result in enumerate(results[:3], 1):
            payload = result.get("payload", {})
            text = payload.get("text", "")[:500]  # 500ì ì œí•œ
            
            if ask_request.source.value == "mail":
                subject = payload.get("mail_subject", "ì œëª© ì—†ìŒ")
                sender = payload.get("sender", "ë°œì†¡ì ë¯¸ìƒ")
                context_parts.append(f"ë©”ì¼ {i}: {subject}\në°œì†¡ì: {sender}\në‚´ìš©: {text}")
                
                references.append({
                    "title": f"{subject} ({sender})",
                    "link": payload.get("link", ""),
                    "type": "mail"
                })
            else:
                doc_name = payload.get("document_name", "ë¬¸ì„œëª… ë¯¸ìƒ")
                context_parts.append(f"ë¬¸ì„œ {i}: {doc_name}\në‚´ìš©: {text}")
                
                references.append({
                    "title": doc_name,
                    "link": payload.get("document_path", ""),
                    "type": "document"
                })
        
        context_text = "\n\n".join(context_parts)
        
        # ì†ŒìŠ¤ë³„ í”„ë¡¬í”„íŠ¸ ìƒì„±
        if ask_request.source.value == "mail":
            system_prompt = dedent(f"""\
                ë‹¹ì‹ ì€ HDí˜„ëŒ€ë¯¸í¬ ì„ ê°ê¸°ìˆ ë¶€ì˜ ë©”ì¼ ê²€ìƒ‰ ë¹„ì„œì…ë‹ˆë‹¤.
                ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.
                
                ì§ˆë¬¸: {ask_request.query}

                ì°¸ê³  ë©”ì¼:
                {context_text}
                
                ë‹µë³€ ê·œì¹™:
                - í•œêµ­ì–´ë¡œë§Œ ë‹µë³€
                - 600ì ì´ë‚´ë¡œ ë‹µë³€  
                - ë¶ˆë¦¿ í¬ì¸íŠ¸ 5ê°œ ì´ë‚´
                - í•µì‹¬ë§Œ ê°„ê²°í•˜ê²Œ
                - ì°¸ê³  ë©”ì¼ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€
                - ë§í¬, URL, ì´ë©”ì¼ ì£¼ì†Œ í¬í•¨ ê¸ˆì§€""")
        else:
            system_prompt = dedent(f"""\
                ë‹¹ì‹ ì€ HDí˜„ëŒ€ë¯¸í¬ ì„ ê°ê¸°ìˆ ë¶€ì˜ ë¬¸ì„œ ê²€ìƒ‰ ë¹„ì„œì…ë‹ˆë‹¤.
                ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.
                
                ì§ˆë¬¸: {ask_request.query}

                ì°¸ê³  ë¬¸ì„œ:
                {context_text}
                
                ë‹µë³€ ê·œì¹™:
                - í•œêµ­ì–´ë¡œë§Œ ë‹µë³€
                - 600ì ì´ë‚´ë¡œ ë‹µë³€
                - ë¶ˆë¦¿ í¬ì¸íŠ¸ 5ê°œ ì´ë‚´
                - í•µì‹¬ë§Œ ê°„ê²°í•˜ê²Œ
                - ì°¸ê³  ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€
                - ë§í¬, URL, íŒŒì¼ ê²½ë¡œ í¬í•¨ ê¸ˆì§€""")
        
        # ResourceManagerë¥¼ í†µí•œ LLM ì‘ë‹µ ìƒì„±
        resource_manager = pipeline.resource_manager
        
        async def gpu_accelerated_stream():
            try:
                # LLM ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ
                response = await resource_manager.generate_llm_response(system_prompt, ask_request.model.value)
                
                # ì‘ë‹µì„ ì²­í¬ë¡œ ë‚˜ëˆ„ì–´ ìŠ¤íŠ¸ë¦¬ë°
                chunks = response.split()
                for i, chunk in enumerate(chunks):
                    if i == len(chunks) - 1:  # ë§ˆì§€ë§‰ ì²­í¬
                        yield json.dumps({
                            "status": "completed",
                            "content": chunk + " ",
                            "references": references,
                            "metadata": {
                                **metadata,
                                "request_id": request_id,
                                "model": request.model.value,
                                "total_results": len(results)
                            }
                        }, ensure_ascii=False)
                    else:
                        yield json.dumps({
                            "status": "streaming", 
                            "content": chunk + " ",
                            "references": []
                        }, ensure_ascii=False)
                        
            except Exception as e:
                logger.error(f"âŒ LLM streaming failed: {e}")
                yield json.dumps({
                    "status": "error",
                    "content": "ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                    "references": references,
                    "metadata": metadata
                }, ensure_ascii=False)
        
        return StreamingResponse(gpu_accelerated_stream(), media_type="application/x-ndjson")
        
    except Exception as e:
        logger.error(f"âŒ GPU RAG failed: {e}")
        error_msg = str(e)  # Capture error message in parent scope
        async def error_stream():
            yield json.dumps({
                "status": "error",
                "content": f"GPU ê°€ì† RAG ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {error_msg}",
                "references": [],
                "metadata": {"request_id": request_id, "error": True}
            }, ensure_ascii=False)
        return StreamingResponse(error_stream(), media_type="application/x-ndjson")


async def ask_legacy(ask_request: AskRequest, request: Request):
    """ë ˆê±°ì‹œ RAG ì—”ë“œí¬ì¸íŠ¸ (GPU ë¯¸ì‚¬ìš©)"""
    request_id = ask_request.request_id
    
    try:
        if not all(k in app_state for k in ["embeddings", "qdrant_clients"]):
            raise HTTPException(status_code=503, detail="ì„œë¹„ìŠ¤ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        logger.info(f"[{request_id}] ğŸ“¨ Legacy Question: {ask_request.query}")
        logger.info(f"[{request_id}] ğŸ“ Source: {ask_request.source.value}")
        
        client = app_state["qdrant_clients"][ask_request.source.value]
        context_text, references = search_qdrant(ask_request.query, request_id, client, config, ask_request.source.value, request)
        
        if not context_text:
            logger.warning(f"[{request_id}] âš ï¸ No context found for question: {ask_request.query}")
        else:
            logger.info(f"[{request_id}] âœ… Context prepared with {len(references)} references")
        
        # sourceì— ë”°ë¥¸ ë©”íƒ€í”„ë¡¬í”„íŠ¸ ë¶„ë¦¬
        if ask_request.source.value == "mail":
            final_prompt = dedent(f"""\
                ë‹¹ì‹ ì€ HDí˜„ëŒ€ë¯¸í¬ ì„ ê°ê¸°ìˆ ë¶€ì˜ ë©”ì¼ ê²€ìƒ‰ ë¹„ì„œì…ë‹ˆë‹¤.
                ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.
                
                ì§ˆë¬¸: {ask_request.query}

                ì°¸ê³  ë©”ì¼:
                {context_text or "ì°¸ê³  ìë£Œ ì—†ìŒ"}
                
                ë‹µë³€ ê·œì¹™:
                - í•œêµ­ì–´ë¡œë§Œ ë‹µë³€
                - 600ì ì´ë‚´ë¡œ ë‹µë³€
                - ë¶ˆë¦¿ í¬ì¸íŠ¸ 5ê°œ ì´ë‚´
                - í•µì‹¬ë§Œ ê°„ê²°í•˜ê²Œ
                - ì°¸ê³  ë©”ì¼ì´ ì œê³µëœ ê²½ìš° ë°˜ë“œì‹œ í•´ë‹¹ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€
                - ì°¸ê³  ë©”ì¼ì´ "ì°¸ê³  ìë£Œ ì—†ìŒ"ì¸ ê²½ìš°ì—ë§Œ "ê´€ë ¨ ë©”ì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤" ì‘ë‹µ
                - ì¤‘ìš”: ë‹µë³€ì—ëŠ” ë§í¬, URL, ì´ë©”ì¼ ì£¼ì†Œë¥¼ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”
                - ì¤‘ìš”: "ë§í¬", "URL", "http", "mailto" ë“±ì˜ ë‹¨ì–´ë¥¼ ë‹µë³€ì— ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”""")
        else:  # source == "doc"
            final_prompt = dedent(f"""\
                ë‹¹ì‹ ì€ HDí˜„ëŒ€ë¯¸í¬ ì„ ê°ê¸°ìˆ ë¶€ì˜ ë¬¸ì„œ ê²€ìƒ‰ ë¹„ì„œì…ë‹ˆë‹¤.
                ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.
                
                ì§ˆë¬¸: {ask_request.query}

                ì°¸ê³  ë¬¸ì„œ:
                {context_text or "ì°¸ê³  ìë£Œ ì—†ìŒ"}
                
                ë‹µë³€ ê·œì¹™:
                - í•œêµ­ì–´ë¡œë§Œ ë‹µë³€
                - 600ì ì´ë‚´ë¡œ ë‹µë³€
                - ë¶ˆë¦¿ í¬ì¸íŠ¸ 5ê°œ ì´ë‚´
                - í•µì‹¬ë§Œ ê°„ê²°í•˜ê²Œ
                - ì°¸ê³  ë¬¸ì„œê°€ ì œê³µëœ ê²½ìš° ë°˜ë“œì‹œ í•´ë‹¹ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€
                - ì°¸ê³  ë¬¸ì„œê°€ "ì°¸ê³  ìë£Œ ì—†ìŒ"ì¸ ê²½ìš°ì—ë§Œ "ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤" ì‘ë‹µ
                - ì¤‘ìš”: ë‹µë³€ì—ëŠ” ë§í¬, URL, íŒŒì¼ ê²½ë¡œë¥¼ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”
                - ì¤‘ìš”: "ë§í¬", "URL", "http", "file://" ë“±ì˜ ë‹¨ì–´ë¥¼ ë‹µë³€ì— ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”""")

        # Ollamaë¡œ ì „ì†¡ë˜ëŠ” ìµœì¢… í”„ë¡¬í”„íŠ¸ ë¡œê¹…
        if DEBUG_MODE:
            logger.info(f"[{request_id}] " + "=" * 60)
            logger.info(f"[{request_id}] ğŸ“® OLLAMA í”„ë¡¬í”„íŠ¸")
            logger.info(f"[{request_id}] " + "=" * 60)
            # í”„ë¡¬í”„íŠ¸ë¥¼ ì¤„ ë‹¨ìœ„ë¡œ ì¶œë ¥ (ë„ˆë¬´ ê¸¸ì–´ì„œ)
            prompt_lines = final_prompt.split('\n')
            for line in prompt_lines[:50]:  # ì²˜ìŒ 50ì¤„ë§Œ
                if line.strip():
                    logger.info(f"[{request_id}] {line}")
            if len(prompt_lines) > 50:
                logger.info(f"[{request_id}] ... (ì´ {len(prompt_lines)}ì¤„, ë‚˜ë¨¸ì§€ ìƒëµ)")
            logger.info(f"[{request_id}] " + "=" * 60)

        async def response_generator():
            full_answer = ""
            async for chunk in stream_llm_response(final_prompt, ask_request.model.value, request_id):
                full_answer += chunk
                yield json.dumps({"answer_chunk": chunk}) + "\n"
            
            yield json.dumps({"references": references}) + "\n"
            
            # dialog_cache.append((request.query, full_answer))  # Commented out for now
            
            # LLM ìµœì¢… ë‹µë³€ ë¡œê¹…
            if DEBUG_MODE:
                logger.info(f"[{request_id}] " + "=" * 60)
                logger.info(f"[{request_id}] ğŸ’¬ LLM ìµœì¢… ë‹µë³€")
                logger.info(f"[{request_id}] " + "=" * 60)
                logger.info(f"[{request_id}] {full_answer}")
                logger.info(f"[{request_id}] " + "=" * 60)

        return StreamingResponse(response_generator(), media_type="application/x-ndjson")

    except Exception as e:
        logger.error(f"[{request_id}] Legacy RAG ì—”ë“œí¬ì¸íŠ¸ì—ì„œ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        if isinstance(e, HTTPException):
            raise e
        raise HTTPException(status_code=500, detail="An internal server error occurred.")
    finally:
        logger.info(f"--- Legacy RAG REQUEST END: {request_id} ---")


# --------------------------------------------------------------------------
# 6. Qdrant ìƒíƒœ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸
# --------------------------------------------------------------------------
@app.get("/api/v2/system/qdrant/status")
async def check_qdrant_status():
    """Qdrant ì„œë²„ ìƒíƒœ í™•ì¸"""
    try:
        from qdrant_client import QdrantClient
        client = QdrantClient(host="127.0.0.1", port=6333, timeout=5.0)
        
        # ì»¬ë ‰ì…˜ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        collections = client.get_collections()
        collection_count = len(collections.collections) if hasattr(collections, 'collections') else 0
        
        return {
            "connected": True,
            "collections": collection_count,
            "host": "127.0.0.1",
            "port": 6333,
            "status": "online"
        }
    except Exception as e:
        logger.warning(f"Qdrant ì—°ê²° ì‹¤íŒ¨: {e}")
        return {
            "connected": False,
            "error": str(e),
            "message": "Qdrant ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Qdrantê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.",
            "host": "127.0.0.1",
            "port": 6333,
            "status": "offline"
        }

# --------------------------------------------------------------------------
# 7. ì„œë²„ ì‹¤í–‰
# --------------------------------------------------------------------------
if __name__ == "__main__":
    import uvicorn
    port = int(os.getenv("RAG_PORT", "8080"))  # ê¸°ë³¸ í¬íŠ¸ë¥¼ 8080ìœ¼ë¡œ
    uvicorn.run(app, host="0.0.0.0", port=port, log_level="info")