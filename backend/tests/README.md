# GPU ê°€ì† ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

ì´ ë””ë ‰í† ë¦¬ì—ëŠ” GPU ê°€ì† RAG ì‹œìŠ¤í…œì˜ Phase 1-4 êµ¬í˜„ì‚¬í•­ì„ ê²€ì¦í•˜ê¸° ìœ„í•œ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ë“¤ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

## ğŸ“ íŒŒì¼ êµ¬ì¡°

```
backend/tests/
â”œâ”€â”€ README.md                   # ì´ íŒŒì¼
â”œâ”€â”€ test_gpu_acceleration.py    # í•µì‹¬ GPU ê°€ì† ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
â”œâ”€â”€ test_api_integration.py     # API ì—”ë“œí¬ì¸íŠ¸ í†µí•© í…ŒìŠ¤íŠ¸  
â””â”€â”€ demo_queue_usage.py         # TaskQueue ì‚¬ìš©ë²• ë°ëª¨
```

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰

```bash
# í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ ì‹¤í–‰
python run_tests.py
```

### 2. ê°œë³„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰

```bash
# GPU ê°€ì† ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
python backend/tests/test_gpu_acceleration.py

# í ì‹œìŠ¤í…œ ì‚¬ìš©ë²• ë°ëª¨
python backend/tests/demo_queue_usage.py

# API í†µí•© í…ŒìŠ¤íŠ¸ (ë°±ì—”ë“œ ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¼ ë•Œ)
python backend/tests/test_api_integration.py --url http://127.0.0.1:8080
```

## ğŸ“ í…ŒìŠ¤íŠ¸ ì„¤ëª…

### `test_gpu_acceleration.py`
**Phase 1-4 êµ¬í˜„ì‚¬í•­ ì¢…í•© ê²€ì¦**

- âœ… **Phase 1**: Import ê²½ë¡œ ìˆ˜ì • í™•ì¸
- âœ… **Phase 2**: Ollama í´ë¼ì´ì–¸íŠ¸ í†µì¼ í…ŒìŠ¤íŠ¸
- âœ… **Phase 3**: ë„¤ì„ìŠ¤í˜ì´ìŠ¤ í™•ì¥ ê²€ì¦
- âœ… **Phase 4**: TaskQueue ê¸°ë°˜ ì§„ì •í•œ í ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
- ğŸš€ **ì„±ëŠ¥ í…ŒìŠ¤íŠ¸**: GPU ê°€ì† ì„ë² ë”© ë²¤ì¹˜ë§ˆí¬
- âš ï¸ **ì—ëŸ¬ ì²˜ë¦¬**: DLQ ë° ì˜ˆì™¸ ì²˜ë¦¬ ê²€ì¦

**ì‹¤í–‰ ì˜ˆì œ:**
```bash
python backend/tests/test_gpu_acceleration.py
```

**ì˜ˆìƒ ì¶œë ¥:**
```
ğŸš€ Starting GPU Acceleration System Tests
âœ… Phase 1: All imports successful
âœ… Phase 2: Ollama client unified (st)
âœ… Phase 3: Collections - Mail: hdmipo_sungak_dev_mail_documents
âœ… Phase 4: Queue system working correctly
ğŸ“ˆ SUMMARY: 6/6 tests passed (100.0%)
```

### `demo_queue_usage.py`
**ìƒˆë¡œìš´ TaskQueue ì‹œìŠ¤í…œ ì‚¬ìš©ë²• ì‹œì—°**

- ğŸ“¤ **ê¸°ë³¸ íì‰**: ì‘ì—…ì„ íì— ì¶”ê°€í•˜ê³  ì²˜ë¦¬ ê³¼ì • ëª¨ë‹ˆí„°ë§
- âš¡ **ìš°ì„ ìˆœìœ„ íì‰**: ìš°ì„ ìˆœìœ„ë³„ ì‘ì—… ì²˜ë¦¬ ìˆœì„œ í™•ì¸
- ğŸ“¦ **ë°°ì¹˜ ì‘ì—…**: ì—¬ëŸ¬ ì‘ì—…ì„ í•œë²ˆì— íì— ì¶”ê°€
- ğŸ‘€ **ì‘ì—… ëª¨ë‹ˆí„°ë§**: ê°œë³„ ì‘ì—… ìƒíƒœ ì¶”ì 
- âš ï¸ **ì—ëŸ¬ ì‹œë‚˜ë¦¬ì˜¤**: ì˜ëª»ëœ ì‘ì—… ì²˜ë¦¬ ë°©ì‹ í™•ì¸

**ì‹¤í–‰ ì˜ˆì œ:**
```bash
python backend/tests/demo_queue_usage.py
```

### `test_api_integration.py` 
**API ì—”ë“œí¬ì¸íŠ¸ì™€ í ì‹œìŠ¤í…œ í†µí•© ê²€ì¦**

- ğŸ¥ **í—¬ìŠ¤ì²´í¬**: `/health` ì—”ë“œí¬ì¸íŠ¸
- ğŸ“Š **ìƒíƒœ í™•ì¸**: `/status` ì—”ë“œí¬ì¸íŠ¸  
- ğŸ’¬ **ìŠ¤íŠ¸ë¦¬ë° ì§ˆì˜ì‘ë‹µ**: `/ask` ì—”ë“œí¬ì¸íŠ¸
- ğŸ”„ **í í†µí•©**: ë™ì‹œ ìš”ì²­ ì²˜ë¦¬ í™•ì¸
- âŒ **ì—ëŸ¬ ì²˜ë¦¬**: API ë ˆë²¨ ì˜ˆì™¸ ì²˜ë¦¬

**ì‹¤í–‰ ì „ ì¤€ë¹„:**
```bash
# ë°±ì—”ë“œ ì„œë²„ ë¨¼ì € ì‹¤í–‰ (ë³„ë„ í„°ë¯¸ë„)
cd backend
python main.py
```

**ì‹¤í–‰ ì˜ˆì œ:**
```bash
python backend/tests/test_api_integration.py
```

## âš™ï¸ í™˜ê²½ ìš”êµ¬ì‚¬í•­

### í•„ìˆ˜ ì˜ì¡´ì„±
```bash
pip install torch sentence-transformers qdrant-client aiohttp asyncio
```

### ì„ íƒì  ì˜ì¡´ì„±
```bash
# GPU ê°€ì†ì„ ìœ„í•œ CUDA (ê¶Œì¥)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

### í™˜ê²½ ë³€ìˆ˜
```bash
# .env íŒŒì¼ì— ì„¤ì •
EMBED_BACKEND=st                    # st|ollama
EMBED_MODEL=BAAI/bge-m3            # ì„ë² ë”© ëª¨ë¸
EMBED_DEVICE=auto                  # auto|cpu|cuda:0
QDRANT_NAMESPACE=hdmipo_sungak     # ë„¤ì„ìŠ¤í˜ì´ìŠ¤
QDRANT_ENV=dev                     # dev|staging|prod
```

## ğŸ”§ í…ŒìŠ¤íŠ¸ êµ¬ì„±

### GPU ê°€ì† í…ŒìŠ¤íŠ¸ ì„¤ì •
```python
# ResourceManager ì„¤ì •
resource_manager = ResourceManager()
await resource_manager.initialize()

# AsyncPipeline ì„¤ì •  
pipeline = AsyncPipeline(
    resource_manager=resource_manager,
    max_concurrent=3,        # ì›Œì»¤ ìˆ˜
    max_queue_size=50        # í í¬ê¸°
)
```

### API í…ŒìŠ¤íŠ¸ ì„¤ì •
```python
# API í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
tester = APIIntegrationTester(base_url="http://127.0.0.1:8080")

# íƒ€ì„ì•„ì›ƒ ì„¤ì •
timeout = aiohttp.ClientTimeout(total=30)
```

## ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ í•´ì„

### ì„±ê³µ ì¼€ì´ìŠ¤
```
âœ… PASS Phase1_ImportFixes        0.023s
âœ… PASS Phase2_OllamaClient       2.456s
     â””â”€ Backend: st
âœ… PASS Phase3_NamespaceExpansion 0.012s  
     â””â”€ Mail: hdmipo_sungak_dev_mail_documents
âœ… PASS Phase4_QueueSystem        8.234s
     â””â”€ Completed: 5
```

### ì‹¤íŒ¨ ì¼€ì´ìŠ¤ ë””ë²„ê¹…
```
âŒ FAIL Phase2_OllamaClient       1.234s
     â””â”€ CUDA not available: No GPU found

âŒ FAIL API_Integration          0.567s
     â””â”€ Connection refused: Server not running
```

## ğŸ› ë¬¸ì œ í•´ê²°

### GPU ê°€ì† ë¬¸ì œ
```bash
# CUDA ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"

# CPUë¡œ í´ë°± ì‹¤í–‰
export EMBED_DEVICE=cpu
python backend/tests/test_gpu_acceleration.py
```

### ì„œë²„ ì—°ê²° ë¬¸ì œ
```bash
# ë°±ì—”ë“œ ì„œë²„ ì‹¤í–‰ í™•ì¸
curl -X GET "http://127.0.0.1:8080/health"

# í¬íŠ¸ ë³€ê²½
python backend/tests/test_api_integration.py --url http://127.0.0.1:8081
```

### ì˜ì¡´ì„± ë¬¸ì œ
```bash
# ëˆ„ë½ëœ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install -r requirements.txt

# ê°œë°œ ì˜ì¡´ì„± ì„¤ì¹˜
pip install pytest pytest-asyncio aiohttp
```

## ğŸ“ˆ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

### ì„ë² ë”© ì„±ëŠ¥ ê¸°ì¤€ê°’

| Device | Batch Size | Texts/Second | Memory Usage |
|--------|-----------|--------------|--------------|
| CPU    | 32        | ~20-30       | ~2GB         |
| GPU    | 64        | ~100-200     | ~4GB         |

### í ì²˜ë¦¬ ì„±ëŠ¥

| Queue Size | Workers | Tasks/Second | Latency |
|-----------|---------|--------------|---------|
| 50        | 2       | ~5-10        | <2s     |
| 100       | 5       | ~15-25       | <1s     |

## ğŸ”„ ì§€ì†ì  í†µí•© (CI)

### GitHub Actions ì„¤ì • ì˜ˆì œ
```yaml
name: GPU Acceleration Tests

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    - uses: actions/setup-python@v4
      with:
        python-version: '3.9'
    - run: pip install -r requirements.txt
    - run: python run_tests.py
```

## ğŸ“š ì¶”ê°€ ìë£Œ

- [GPU ê°€ì† êµ¬í˜„ ê°€ì´ë“œ](../docs/gpu_acceleration_guide.md)
- [TaskQueue API ë¬¸ì„œ](../pipeline/task_queue.py)
- [ResourceManager ì„¤ì •](../resource_manager.py)
- [í™˜ê²½ ì„¤ì • ê°€ì´ë“œ](../../.env.example)

---

**ì‘ì„±ì**: Claude Code  
**ìµœì¢… ìˆ˜ì •**: 2025-01-27  
**ë²„ì „**: 1.0