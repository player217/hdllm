"""
GPU ê°€ì† ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
Author: Claude Code  
Date: 2025-01-27
Description: Phase 1-4 êµ¬í˜„ì‚¬í•­ ê²€ì¦ì„ ìœ„í•œ ì¢…í•© í…ŒìŠ¤íŠ¸
"""

import asyncio
import time
import logging
import sys
import os
from pathlib import Path

# ìƒìœ„ ë””ë ‰í† ë¦¬ ê²½ë¡œ ì¶”ê°€
sys.path.append(str(Path(__file__).parent.parent))

from backend.resource_manager import ResourceManager
from backend.pipeline.async_pipeline import AsyncPipeline
from backend.pipeline.task_queue import TaskQueue, QueueTask, TaskStatus

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(name)s - %(message)s'
)
logger = logging.getLogger(__name__)

class GPUAccelerationTester:
    """GPU ê°€ì† ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤í„°"""
    
    def __init__(self):
        self.resource_manager = None
        self.pipeline = None
        self.test_results = []
    
    async def setup(self):
        """í…ŒìŠ¤íŠ¸ í™˜ê²½ ì„¤ì •"""
        logger.info("ğŸš€ Setting up test environment...")
        
        try:
            # ResourceManager ì´ˆê¸°í™”
            self.resource_manager = ResourceManager()
            await self.resource_manager.initialize()
            
            # AsyncPipeline ì´ˆê¸°í™”
            self.pipeline = AsyncPipeline(
                resource_manager=self.resource_manager,
                max_concurrent=3,
                max_queue_size=50
            )
            
            # í ì‹œìŠ¤í…œ ì‹œì‘
            await self.pipeline.start_queue()
            
            logger.info("âœ… Test environment setup complete")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Setup failed: {e}")
            return False
    
    async def teardown(self):
        """í…ŒìŠ¤íŠ¸ í™˜ê²½ ì •ë¦¬"""
        logger.info("ğŸ§¹ Cleaning up test environment...")
        
        try:
            if self.pipeline:
                await self.pipeline.stop_queue()
            
            if self.resource_manager:
                await self.resource_manager.cleanup()
            
            logger.info("âœ… Cleanup complete")
            
        except Exception as e:
            logger.error(f"âš ï¸ Cleanup warning: {e}")
    
    def record_result(self, test_name: str, success: bool, duration: float, details: str = ""):
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ê¸°ë¡"""
        self.test_results.append({
            "test": test_name,
            "success": success,
            "duration": duration,
            "details": details
        })
    
    async def test_phase1_import_fixes(self):
        """Phase 1: Import ê²½ë¡œ ìˆ˜ì • í…ŒìŠ¤íŠ¸"""
        logger.info("ğŸ” Testing Phase 1: Import path fixes...")
        start_time = time.time()
        
        try:
            # ì ˆëŒ€ ê²½ë¡œ import í…ŒìŠ¤íŠ¸
            from backend.pipeline.async_pipeline import AsyncPipeline
            from backend.common.schemas import AskRequest
            from backend.resource_manager import ResourceManager
            
            logger.info("âœ… Phase 1: All imports successful")
            self.record_result("Phase1_ImportFixes", True, time.time() - start_time)
            return True
            
        except ImportError as e:
            logger.error(f"âŒ Phase 1: Import failed - {e}")
            self.record_result("Phase1_ImportFixes", False, time.time() - start_time, str(e))
            return False
    
    async def test_phase2_ollama_client(self):
        """Phase 2: Ollama í´ë¼ì´ì–¸íŠ¸ í†µì¼ í…ŒìŠ¤íŠ¸"""
        logger.info("ğŸ” Testing Phase 2: Ollama client unification...")
        start_time = time.time()
        
        try:
            # ResourceManagerì˜ embed_texts ë©”ì„œë“œ í…ŒìŠ¤íŠ¸
            test_texts = ["í…ŒìŠ¤íŠ¸ ë¬¸ì¥ì…ë‹ˆë‹¤.", "GPU ê°€ì†ì´ ì‘ë™í•˜ë‚˜ìš”?"]
            
            embeddings = await self.resource_manager.embed_texts(test_texts)
            
            # ê²°ê³¼ ê²€ì¦
            assert len(embeddings) == len(test_texts), f"Expected {len(test_texts)} embeddings, got {len(embeddings)}"
            assert all(len(emb) == 1024 for emb in embeddings), "All embeddings should be 1024-dimensional"
            
            # ë°±ì—”ë“œë³„ í…ŒìŠ¤íŠ¸
            backend = self.resource_manager.embed_backend
            if backend == "ollama":
                # Ollama í†µì¼ í´ë¼ì´ì–¸íŠ¸ í…ŒìŠ¤íŠ¸
                logger.info("ğŸ”§ Testing unified Ollama client...")
                embedding = await self.resource_manager.ollama_bucket.generate_embedding(
                    model=self.resource_manager.embed_model,
                    text="í†µì¼ëœ í´ë¼ì´ì–¸íŠ¸ í…ŒìŠ¤íŠ¸"
                )
                assert len(embedding) == 1024, "Unified client should return 1024-dim embedding"
            
            logger.info(f"âœ… Phase 2: Ollama client unified ({backend})")
            self.record_result("Phase2_OllamaClient", True, time.time() - start_time, f"Backend: {backend}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Phase 2: Ollama client test failed - {e}")
            self.record_result("Phase2_OllamaClient", False, time.time() - start_time, str(e))
            return False
    
    async def test_phase3_namespace_expansion(self):
        """Phase 3: ë„¤ì„ìŠ¤í˜ì´ìŠ¤ í™•ì¥ í…ŒìŠ¤íŠ¸"""
        logger.info("ğŸ” Testing Phase 3: Namespace expansion...")
        start_time = time.time()
        
        try:
            config = self.resource_manager.config
            
            # ë™ì  ì»¬ë ‰ì…˜ëª… ìƒì„± í…ŒìŠ¤íŠ¸
            mail_collection = config.get_collection_name("mail", "documents")
            doc_collection = config.get_collection_name("doc", "documents")
            
            # ì˜ˆìƒ í˜•ì‹: {namespace}_{env}_{source}_{base}
            expected_pattern = f"{config.qdrant_namespace}_{config.qdrant_env}_"
            
            assert mail_collection.startswith(expected_pattern), f"Mail collection should start with {expected_pattern}"
            assert doc_collection.startswith(expected_pattern), f"Doc collection should start with {expected_pattern}"
            assert "mail" in mail_collection, "Mail collection should contain 'mail'"
            assert "doc" in doc_collection, "Doc collection should contain 'doc'"
            
            logger.info(f"âœ… Phase 3: Collections - Mail: {mail_collection}, Doc: {doc_collection}")
            self.record_result("Phase3_NamespaceExpansion", True, time.time() - start_time, 
                             f"Mail: {mail_collection}, Doc: {doc_collection}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Phase 3: Namespace expansion test failed - {e}")
            self.record_result("Phase3_NamespaceExpansion", False, time.time() - start_time, str(e))
            return False
    
    async def test_phase4_queue_system(self):
        """Phase 4: ì§„ì •í•œ í ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
        logger.info("ğŸ” Testing Phase 4: True queue system...")
        start_time = time.time()
        
        try:
            # 1. ê¸°ë³¸ í ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
            queue_stats_before = self.pipeline.get_queue_stats()
            logger.info(f"ğŸ“Š Queue stats before: {queue_stats_before}")
            
            # 2. ê²€ìƒ‰ ì‘ì—… íì‰ í…ŒìŠ¤íŠ¸
            search_payload = {
                "query": "GPU ê°€ì† í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬",
                "source_type": "mail",
                "limit": 3,
                "score_threshold": 0.3
            }
            
            task_id = await self.pipeline.enqueue("search", search_payload, priority=1)
            logger.info(f"ğŸ“¤ Search task enqueued: {task_id}")
            
            # 3. ì„ë² ë”© ì‘ì—… íì‰ í…ŒìŠ¤íŠ¸  
            embed_payload = {
                "text": "ì„ë² ë”© í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸",
                "document_id": "test_doc_001",
                "chunk_idx": 0
            }
            
            embed_task_id = await self.pipeline.enqueue("embed", embed_payload, priority=2)
            logger.info(f"ğŸ“¤ Embed task enqueued: {embed_task_id}")
            
            # 4. ë°°ì¹˜ íì‰ í…ŒìŠ¤íŠ¸
            batch_tasks = [
                {"task_type": "search", "payload": {"query": "ë°°ì¹˜ í…ŒìŠ¤íŠ¸ 1", "source_type": "mail"}, "priority": 0},
                {"task_type": "search", "payload": {"query": "ë°°ì¹˜ í…ŒìŠ¤íŠ¸ 2", "source_type": "doc"}, "priority": 0},
                {"task_type": "embed", "payload": {"text": "ë°°ì¹˜ ì„ë² ë”© í…ŒìŠ¤íŠ¸", "document_id": "batch_001"}, "priority": 1}
            ]
            
            batch_task_ids = await self.pipeline.enqueue_batch(batch_tasks)
            logger.info(f"ğŸ“¦ Batch tasks enqueued: {len([t for t in batch_task_ids if t])} successful")
            
            # 5. ì‘ì—… ì§„í–‰ ëŒ€ê¸° (ìµœëŒ€ 30ì´ˆ)
            max_wait = 30
            wait_time = 0
            
            while wait_time < max_wait:
                queue_stats = self.pipeline.get_queue_stats()
                processing_tasks = queue_stats.get("processing_tasks", 0)
                pending_tasks = queue_stats.get("pending_tasks", 0)
                completed_tasks = queue_stats.get("total_completed", 0)
                
                logger.info(f"ğŸ“Š Queue status - Pending: {pending_tasks}, Processing: {processing_tasks}, Completed: {completed_tasks}")
                
                if pending_tasks == 0 and processing_tasks == 0:
                    logger.info("âœ… All tasks completed")
                    break
                
                await asyncio.sleep(2)
                wait_time += 2
            
            # 6. ìµœì¢… í†µê³„ í™•ì¸
            final_stats = self.pipeline.get_queue_stats()
            logger.info(f"ğŸ“Š Final queue stats: {final_stats}")
            
            # ê²€ì¦
            assert final_stats.get("total_completed", 0) > 0, "Some tasks should be completed"
            assert final_stats.get("total_failed", 0) >= 0, "Failed tasks count should be non-negative"
            
            logger.info("âœ… Phase 4: Queue system working correctly")
            self.record_result("Phase4_QueueSystem", True, time.time() - start_time,
                             f"Completed: {final_stats.get('total_completed', 0)}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Phase 4: Queue system test failed - {e}")
            self.record_result("Phase4_QueueSystem", False, time.time() - start_time, str(e))
            return False
    
    async def test_gpu_performance(self):
        """GPU ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸"""
        logger.info("ğŸ” Testing GPU Performance...")
        start_time = time.time()
        
        try:
            # ë‹¤ì–‘í•œ í¬ê¸°ì˜ í…ìŠ¤íŠ¸ ë°°ì¹˜ í…ŒìŠ¤íŠ¸
            test_batches = [
                ["ì§§ì€ í…ìŠ¤íŠ¸"],
                ["ì¤‘ê°„ ê¸¸ì´ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤. " * 5] * 5,
                ["ê¸´ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤. " * 20] * 10,
                ["ë§¤ìš° ê¸´ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤. " * 50] * 20
            ]
            
            performance_results = []
            
            for i, batch in enumerate(test_batches):
                batch_start = time.time()
                embeddings = await self.resource_manager.embed_texts(batch)
                batch_time = time.time() - batch_start
                
                perf_data = {
                    "batch_size": len(batch),
                    "avg_text_length": sum(len(text) for text in batch) // len(batch),
                    "duration": batch_time,
                    "texts_per_second": len(batch) / batch_time if batch_time > 0 else 0
                }
                performance_results.append(perf_data)
                
                logger.info(f"ğŸ“Š Batch {i+1}: {len(batch)} texts, {batch_time:.3f}s, "
                           f"{perf_data['texts_per_second']:.1f} texts/sec")
            
            # í‰ê·  ì„±ëŠ¥ ê³„ì‚°
            avg_tps = sum(p['texts_per_second'] for p in performance_results) / len(performance_results)
            device = self.resource_manager.embed_device
            
            logger.info(f"âœ… GPU Performance: Average {avg_tps:.1f} texts/sec on {device}")
            self.record_result("GPU_Performance", True, time.time() - start_time,
                             f"Avg: {avg_tps:.1f} texts/sec, Device: {device}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ GPU Performance test failed - {e}")
            self.record_result("GPU_Performance", False, time.time() - start_time, str(e))
            return False
    
    async def test_error_handling(self):
        """ì—ëŸ¬ ì²˜ë¦¬ ë° DLQ í…ŒìŠ¤íŠ¸"""
        logger.info("ğŸ” Testing Error Handling and DLQ...")
        start_time = time.time()
        
        try:
            # 1. ì˜ëª»ëœ ì‘ì—… íƒ€ì… í…ŒìŠ¤íŠ¸
            try:
                await self.pipeline.enqueue("invalid_type", {})
                assert False, "Should have raised an error for invalid task type"
            except ValueError:
                logger.info("âœ… Invalid task type properly rejected")
            
            # 2. ë¹ˆ í˜ì´ë¡œë“œ í…ŒìŠ¤íŠ¸  
            try:
                await self.pipeline.enqueue("search", {})
                # ì´ê²ƒì€ ì‹¤íŒ¨í•  ìˆ˜ ìˆì§€ë§Œ DLQì— ë“¤ì–´ê°€ì•¼ í•¨
                logger.info("âš ï¸ Empty payload handled (may fail gracefully)")
            except Exception:
                logger.info("âœ… Empty payload error handled")
            
            # 3. DLQ í†µê³„ í™•ì¸
            await asyncio.sleep(2)  # ì²˜ë¦¬ ëŒ€ê¸°
            dlq_stats = self.pipeline.dlq.get_stats()
            logger.info(f"ğŸ“Š DLQ Stats: {dlq_stats}")
            
            # 4. í ìƒíƒœ í†µê³„
            queue_stats = self.pipeline.get_queue_stats()
            logger.info(f"ğŸ“Š Queue Stats: {queue_stats}")
            
            logger.info("âœ… Error handling and DLQ working")
            self.record_result("ErrorHandling_DLQ", True, time.time() - start_time,
                             f"DLQ entries: {dlq_stats.get('total_entries', 0)}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Error handling test failed - {e}")
            self.record_result("ErrorHandling_DLQ", False, time.time() - start_time, str(e))
            return False
    
    def print_results(self):
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì¶œë ¥"""
        logger.info("\n" + "="*60)
        logger.info("ğŸ“Š GPU ACCELERATION TEST RESULTS")
        logger.info("="*60)
        
        total_tests = len(self.test_results)
        passed_tests = sum(1 for r in self.test_results if r["success"])
        total_time = sum(r["duration"] for r in self.test_results)
        
        for result in self.test_results:
            status = "âœ… PASS" if result["success"] else "âŒ FAIL"
            logger.info(f"{status} {result['test']:<25} {result['duration']:.3f}s")
            if result["details"]:
                logger.info(f"     â””â”€ {result['details']}")
        
        logger.info("-"*60)
        logger.info(f"ğŸ“ˆ SUMMARY: {passed_tests}/{total_tests} tests passed ({passed_tests/total_tests*100:.1f}%)")
        logger.info(f"â±ï¸  TOTAL TIME: {total_time:.3f} seconds")
        logger.info("="*60)
        
        return passed_tests == total_tests
    
    async def run_all_tests(self):
        """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        logger.info("ğŸš€ Starting GPU Acceleration System Tests")
        
        # í™˜ê²½ ì„¤ì •
        if not await self.setup():
            logger.error("âŒ Setup failed, aborting tests")
            return False
        
        try:
            # Phaseë³„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
            tests = [
                self.test_phase1_import_fixes,
                self.test_phase2_ollama_client,
                self.test_phase3_namespace_expansion,
                self.test_phase4_queue_system,
                self.test_gpu_performance,
                self.test_error_handling
            ]
            
            for test in tests:
                try:
                    await test()
                except Exception as e:
                    logger.error(f"âŒ Test {test.__name__} crashed: {e}")
                    self.record_result(test.__name__, False, 0, f"Crashed: {e}")
                
                # í…ŒìŠ¤íŠ¸ ê°„ ê°„ê²©
                await asyncio.sleep(1)
        
        finally:
            # í™˜ê²½ ì •ë¦¬
            await self.teardown()
        
        # ê²°ê³¼ ì¶œë ¥
        return self.print_results()


async def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    tester = GPUAccelerationTester()
    success = await tester.run_all_tests()
    
    if success:
        logger.info("ğŸ‰ All tests passed!")
        return 0
    else:
        logger.error("ğŸ’¥ Some tests failed!")
        return 1


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)